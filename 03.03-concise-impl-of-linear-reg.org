#+PROPERTY: header-args    :tangle src/clj_d2l/linreg_easy.clj
* Concise Implementation of Linear Regression

** Generating the Dataset

#+begin_src clojure :results silent
(ns clj-d2l.linreg-easy
  (:require [clojure.java.io :as io]
            [clj-djl.ndarray :as nd]
            [clj-djl.device :as device]
            [clj-djl.engine :as engine]
            [clj-djl.training.dataset :as ds]
            [clj-djl.model :as model]
            [clj-djl.nn :as nn]
            [clj-djl.training.loss :as loss]
            [clj-djl.training.tracker :as tracker]
            [clj-djl.training.optimizer :as optimizer]
            [clj-djl.training :as training]
            [clj-djl.training.listener :as listener])
  (:import [ai.djl.ndarray.types DataType]
           [java.nio.file Paths]))
#+end_src

#+begin_src clojure :results output :exports both
(defn synthetic-data [ndm w b num]
  (let [X (nd/random-normal ndm [num (nd/size w)])
        y (nd/+ (nd/dot X w) b)
        noise (nd/random-normal ndm 0 0.01 (nd/get-shape y) DataType/FLOAT32)]
    [X (nd/+ y noise)]))

(def ndm (nd/new-base-manager))
(def true-w (nd/create ndm (float-array [2 -3.4])))
(def true-b 4.2)
(def dp (synthetic-data ndm true-w true-b 1000))
(def features (get dp 0))
(def labels (get dp 1))
(println "features(0): "(nd/to-vec (nd/get features [0])))
(println "labels(0): " (nd/get-element labels [0]))
#+end_src

#+RESULTS:
: features(0):  [2.2122064 1.1630787]
: labels(0):  4.662078


** Reading the Dataset

#+begin_src clojure :results silent :exports both
(def batch-size 10)
(def dataset (-> (ds/new-array-dataset-builder)
                 (ds/set-data features)
                 (ds/opt-labels labels)
                 (ds/set-sampling batch-size false)
                 (ds/build)))
#+end_src

* Defining the Model

#+begin_src clojure :results silent :exports both
(def model (model/new-instance "lin-reg"))
(def net (nn/sequential-block))
(def linear-block (-> (nn/new-linear-builder) (nn/opt-bias true) (nn/set-units 1) (nn/build)))
(nn/add net linear-block)
(model/set-block model net)
#_(def linear-block (nn/linear {:opt-bias true
                                :units 1}))
#+end_src


** Defining the Loss Function

#+begin_src clojure :results silent :exports both
(def loss (loss/l2-loss))
#+end_src


** Defining the Optimization Algorithm

#+begin_src clojure :results silent :exports both
(def lrt (tracker/fixed 0.3))
(def sgd (-> (optimizer/sgd) (optimizer/set-learning-rate-tracker lrt) (optimizer/build)))
#+end_src


** Instantiate Configuration and Trainer

#+begin_src clojure :results silent :exports both
(def config (-> (training/new-default-training-config loss)
                (training/opt-optimizer sgd)
                (training/add-training-listeners (listener/logging))))
(def trainer (model/new-trainer model config))
#+end_src


** Initializing Model Parameters

#+begin_src clojure :results silent :exports both
(training/initialize trainer [(nd/shape batch-size 2)])
#+end_src


** Metrics

#+begin_src clojure :results silent :exports both
(def metrics (training/metrics))
(training/set-metrics trainer metrics)
#+end_src


** Training

#+begin_src clojure :results output :exports both
(def epochs 3)

(doseq [epoch (range epochs)]
  (doseq [batch (training/iterate-dataset trainer dataset)]
    (training/train-batch trainer batch)
    (training/step trainer)
    (ds/close-batch batch))
  (training/notify-listeners trainer (fn [listner] (.onEpoch listner trainer))))
#+end_src

#+RESULTS:
#+begin_example

Training:      1% |█                                       | L2Loss: _
Training:      2% |█                                       | L2Loss: _
Training:      3% |██                                      | L2Loss: _
Training:      4% |██                                      | L2Loss: _
Training:      5% |███                                     | L2Loss: 6.83
Training:      6% |███                                     | L2Loss: 6.83
Training:      7% |███                                     | L2Loss: 6.83
Training:      8% |████                                    | L2Loss: 6.83
Training:      9% |████                                    | L2Loss: 6.83
Training:     10% |█████                                   | L2Loss: 3.45
Training:     20% |█████████                               | L2Loss: 1.73
Training:     30% |█████████████                           | L2Loss: 1.15
Training:     40% |█████████████████                       | L2Loss: 0.86
Training:     50% |█████████████████████                   | L2Loss: 0.69
Training:     60% |█████████████████████████               | L2Loss: 0.58
Training:     70% |█████████████████████████████           | L2Loss: 0.49
Training:     80% |█████████████████████████████████       | L2Loss: 0.43
Training:     90% |█████████████████████████████████████   | L2Loss: 0.38
Training:    100% |████████████████████████████████████████| L2Loss: 0.35
Training:      1% |█                                       | L2Loss: 0.35
Training:      2% |█                                       | L2Loss: 0.35
Training:      3% |██                                      | L2Loss: 0.35
Training:      4% |██                                      | L2Loss: 0.35
Training:      5% |███                                     | L2Loss: 4.90E-05
Training:      6% |███                                     | L2Loss: 4.90E-05
Training:      7% |███                                     | L2Loss: 4.90E-05
Training:      8% |████                                    | L2Loss: 4.90E-05
Training:      9% |████                                    | L2Loss: 4.90E-05
Training:     10% |█████                                   | L2Loss: 4.47E-05
Training:     20% |█████████                               | L2Loss: 5.39E-05
Training:     30% |█████████████                           | L2Loss: 5.40E-05
Training:     40% |█████████████████                       | L2Loss: 5.12E-05
Training:     50% |█████████████████████                   | L2Loss: 5.70E-05
Training:     60% |█████████████████████████               | L2Loss: 5.75E-05
Training:     70% |█████████████████████████████           | L2Loss: 5.76E-05
Training:     80% |█████████████████████████████████       | L2Loss: 5.71E-05
Training:     90% |█████████████████████████████████████   | L2Loss: 5.61E-05
Training:    100% |████████████████████████████████████████| L2Loss: 5.51E-05
Training:      1% |█                                       | L2Loss: 5.51E-05
Training:      2% |█                                       | L2Loss: 5.51E-05
Training:      3% |██                                      | L2Loss: 5.51E-05
Training:      4% |██                                      | L2Loss: 5.51E-05
Training:      5% |███                                     | L2Loss: 4.90E-05
Training:      6% |███                                     | L2Loss: 4.90E-05
Training:      7% |███                                     | L2Loss: 4.90E-05
Training:      8% |████                                    | L2Loss: 4.90E-05
Training:      9% |████                                    | L2Loss: 4.90E-05
Training:     10% |█████                                   | L2Loss: 4.47E-05
Training:     20% |█████████                               | L2Loss: 5.39E-05
Training:     30% |█████████████                           | L2Loss: 5.40E-05
Training:     50% |█████████████████████                   | L2Loss: 5.70E-05
Training:     60% |█████████████████████████               | L2Loss: 5.75E-05
Training:     70% |█████████████████████████████           | L2Loss: 5.76E-05
Training:     80% |█████████████████████████████████       | L2Loss: 5.71E-05
Training:     90% |█████████████████████████████████████   | L2Loss: 5.61E-05
Training:    100% |████████████████████████████████████████| L2Loss: 5.51E-05
[nREPL-session-1668919d-4e1e-4463-b305-8ea719072cc6] INFO ai.djl.training.listener.LoggingTrainingListener - Epoch 1 finished.
[nREPL-session-1668919d-4e1e-4463-b305-8ea719072cc6] INFO ai.djl.training.listener.LoggingTrainingListener - Train: L2Loss: 0.35
[nREPL-session-1668919d-4e1e-4463-b305-8ea719072cc6] INFO ai.djl.training.listener.LoggingTrainingListener - Epoch 2 finished.
[nREPL-session-1668919d-4e1e-4463-b305-8ea719072cc6] INFO ai.djl.training.listener.LoggingTrainingListener - Train: L2Loss: 5.51E-05
[nREPL-session-1668919d-4e1e-4463-b305-8ea719072cc6] INFO ai.djl.training.listener.LoggingTrainingListener - Epoch 3 finished.
[nREPL-session-1668919d-4e1e-4463-b305-8ea719072cc6] INFO ai.djl.training.listener.LoggingTrainingListener - Train: L2Loss: 5.51E-05
#+end_example

#+begin_src clojure :results output :exports both
(def params (-> model (model/get-block) (model/get-parameters)))
(def w (.getArray (.valueAt params 0)))
(def b (.getArray (.valueAt params 1)))
(def w-error (nd/to-vec (nd/- true-w (nd/reshape w (nd/get-shape true-w)))))
(println "Error in estimating w:" (vec w-error))
(println "Error in estimating w:" (- true-b (nd/get-element b)))
#+end_src

#+RESULTS:
: Error in estimating w: [0.0013849735 -0.0010635853]
: Error in estimating w: 1.0366439819353701E-4

** Saving Your Model

#+begin_src clojure :results output :exports both
(defn save-model [model path epoch name]
  (let [nio-path (java.nio.file.Paths/get path (into-array [""]))]
    (io/make-parents path)
    (model/set-property model "Epoch" epoch)
    (model/save model nio-path name)))

(save-model model "models/lin-reg" "3" "lin-reg")
(println (str model))
#+end_src

#+RESULTS:
: Model (
: 	Name: lin-reg
: 	Model location: /home/kimim/workspace/clj-d2l/models/lin-reg
: 	Data Type: float32
: 	Epoch: 3
: )
