* Multilayer Perceptrons

#+begin_src clojure :results silent :exports both
(ns clj-d2l.multilayer-perceptrons
  (:require [clojure.java.io :as io]
            [clj-djl.ndarray :as nd]
            [clj-djl.engine :as engine]
            [clj-djl.model :as model]
            [clj-djl.nn :as nn]
            [clj-djl.training :as training]
            [clj-djl.training.loss :as loss]
            [clj-djl.training.tracker :as tracker]
            [clj-djl.training.optimizer :as optimizer]
            [clj-djl.training.listener :as listener]
            [clj-djl.metric :as metric]
            [com.hypirion.clj-xchart :as c]))
#+end_src

** Hidden Layers

*** Incorporating Hidden Layers

*** From Linear to Nonlinear

*** Vectorization and Minibatch

** Activation Functions

*** ReLU Function

rectified linear unit:

#+begin_export latex
\begin{equation}
ReLU(z) = max(z, 0)
\end{equation}
#+end_export

#+begin_src clojure :results silent :exports both
(def manager (nd/new-base-manager))
(def x (nd/arange manager -8.0 8.0 0.1))
(nd/attach-gradient x)
(def y (nn/relu x))

(def X (nd/to-vec x))
(def Y (nd/to-vec y))

(-> (c/xy-chart
     {"ReLU"
      {:x X
       :y Y
       :style {:marker-type :none}}})
    (c/spit "figure/relu.svg"))
#+end_src

#+RESULTS:
[[./figure/relu.svg]]

#+begin_src clojure :results silent
(try
  (let [gc (-> (engine/get-instance) (engine/new-gradient-collector))
        y (nn/relu x)]
    (.backward gc y)))
(def res (nd/get-gradient x))

(def X (nd/to-vec x))
(def Y (nd/to-vec res))

(-> (c/xy-chart
     {"grad of ReLU"
      {:x X
       :y Y
       :style {:marker-type :none}}})
    (c/spit "figure/grad_relu.svg"))
#+end_src

[[./figure/grad_relu.svg]]
