<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2022-05-17 Tue 07:53 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>&lrm;</title>
<meta name="author" content="Kimi Ma" />
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
</style>
<link rel="stylesheet" type="text/css" href="css/style.css" />
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="org-div-home-and-up">
 <a accesskey="h" href="sitemap.html"> UP </a>
 |
 <a accesskey="H" href="index.html"> HOME </a>
</div><div id="content" class="content">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org688e275">1. Linear Algebra</a>
<ul>
<li><a href="#org05a3040">1.1. Scalars</a></li>
<li><a href="#org8c5b9ca">1.2. Vectors</a></li>
<li><a href="#org9c9b160">1.3. Length, Dimensionality, and Shape</a></li>
<li><a href="#orgeed1b80">1.4. Matrices</a></li>
<li><a href="#org988f23b">1.5. Tensors / NDArrays</a></li>
<li><a href="#org2aebf18">1.6. Basic Properties of Tensor Arithmetic</a></li>
<li><a href="#lin-alg-reduction">1.7. Reduction</a>
<ul>
<li><a href="#lin-alg-non-reduction">1.7.1. Non-Reduction Sum</a></li>
</ul>
</li>
<li><a href="#org8b72aeb">1.8. Dot Products</a></li>
<li><a href="#org069ddea">1.9. Matrix-Vector Products</a></li>
<li><a href="#org179830c">1.10. Matrix-Matrix Multiplication</a></li>
<li><a href="#org01d1f21">1.11. Norms</a></li>
<li><a href="#org5fbc90e">1.12. Norms and Objectives</a></li>
<li><a href="#org0f3a939">1.13. More on Linear Algebra</a></li>
<li><a href="#org3769a94">1.14. Summary</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org688e275" class="outline-2">
<h2 id="org688e275"><span class="section-number-2">1.</span> Linear Algebra</h2>
<div class="outline-text-2" id="text-1">
<p>
Now that you can store and manipulate data, let us briefly review the
subset of basic linear algebra that you will need to understand and
implement most of models covered in this book. Below, we introduce the
basic mathematical objects, arithmetic, and operations in linear
algebra, expressing each of them through mathematical notation and the
corresponding implementation in code.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">ns</span> <span style="color: #000000; font-style: italic; text-decoration: underline;">clj-d2l.linear-algebra</span>
  <span style="color: #7388d6;">(</span><span style="color: #110099;">:require</span> <span style="color: #909183;">[</span>clj-djl.ndarray <span style="color: #110099;">:as</span> nd<span style="color: #909183;">]</span>
            <span style="color: #909183;">[</span>clj-d2l.core <span style="color: #110099;">:as</span> d2l<span style="color: #909183;">]</span>
            <span style="color: #909183;">[</span>clojure.java.io <span style="color: #110099;">:as</span> io<span style="color: #909183;">]</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
</pre>
</div>
</div>

<div id="outline-container-org05a3040" class="outline-3">
<h3 id="org05a3040"><span class="section-number-3">1.1.</span> Scalars</h3>
<div class="outline-text-3" id="text-1-1">
<p>
If you never studied linear algebra or machine learning, then your
past experience with math probably consisted of thinking about one
number at a time. And, if you ever balanced a checkbook or even paid
for dinner at a restaurant then you already know how to do basic
things like adding and multiplying pairs of numbers. For example, the
temperature in Palo Alto is \(52\) degrees Fahrenheit. Formally, we call
values consisting of just one numerical quantity <i>scalars</i>. If you
wanted to convert this value to Celsius (the metric system&rsquo;s more
sensible temperature scale), you would evaluate the expression
\(c=\frac{5}{9}(f−32)\), setting \(f\) to \(52\). In this equation, each of
the terms — \(5\), \(9\), and \(32\) — are scalar values. The placeholders
\(c\) and \(f\) are called <i>variables</i> and they represent unknown scalar
values. We denote the space of all (continuous) real-valued scalars by
\(\mathbb{R}\).
</p>

<p>
In this book, we adopt the mathematical notation where scalar
variables are denoted by ordinary lower-cased letters (e.g., \(x\), \(y\),
and \(z\)). For expedience, we will punt on rigorous definitions of what
precisely <b>space</b> is, but just remember for now that the expression \(x
\in \mathbb{R}\) is a formal way to say that \(x\) is a <i>real-valued
scalar</i>. The symbol \(\in\) can be pronounced &ldquo;in&rdquo; and simply denotes
membership in a set. Analogously, we could write \(x, y \in \{0,1\}\) to
state that \(x\) and \(y\) are numbers whose value can only be \(0\) or \(1\).
</p>

<p>
A scalar is represented by a NDArray with just one element. In the
next snippet, we instantiate two scalars and perform some familiar
arithmetic operations with them, namely addition, multiplication,
division, and exponentiation.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">ndm</span> <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/base-manager<span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
<span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">x</span> <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/create ndm 3.<span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
<span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">y</span> <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/create ndm 2.<span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
</pre>
</div>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/+ x y<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: () cpu() float64
5.
</pre>


<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/* x y<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: () cpu() float64
6.
</pre>


<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>// x y<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: () cpu() float64
1.5
</pre>


<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/pow x y<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: () cpu() float64
9.
</pre>
</div>
</div>

<div id="outline-container-org8c5b9ca" class="outline-3">
<h3 id="org8c5b9ca"><span class="section-number-3">1.2.</span> Vectors</h3>
<div class="outline-text-3" id="text-1-2">
<p>
You can think of a vector as simply a list of scalar values. We call
these values the <i>elements</i> (<i>entries</i> or <i>components</i>) of the vector. When
our vectors represent examples from our dataset, their values hold
some real-world significance. For example, if we were training a model
to predict the risk that a loan defaults, we might associate each
applicant with a vector whose components correspond to their income,
length of employment, number of previous defaults, and other
factors. If we were studying the risk of heart attacks hospital
patients potentially face, we might represent each patient by a vector
whose components capture their most recent vital signs, cholesterol
levels, minutes of exercise per day, etc. In math notation, we will
usually denote vectors as bold-faced, lower-cased letters (e.g.,
\(\mathbf{x}\), \(\mathbf{y}\), and \(\mathbf{z}\).
</p>

<p>
We work with vectors via one-dimensional NDArrays. In general NDArrays
can have arbitrary lengths, subject to the memory limits of your
machine.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">x</span> <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/arange ndm 4.<span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
x
</pre>
</div>

<pre class="example">
ND: (4) cpu() float32
[0., 1., 2., 3.]
</pre>


<p>
We can refer to any element of a vector by using a subscript. For
example, we can refer to the i<sup>th</sup> element of \(\mathbf{x}\) by
\(x_i\). Note that the element \(x_i\) is a scalar, so we do not bold-face
the font when referring to it. Extensive literature considers column
vectors to be the default orientation of vectors, so does this
book. In math, a vector \(\mathbf{x}\) can be written as
</p>

\begin{equation}
\mathbf{x} =  \begin{bmatrix} x_1 \\ x_2 \\ \vdots \\ x_n \end{bmatrix},
\end{equation}


<p>
where \(x_1, \ldots, x_n\) are elements of the vector. In code, we
access any element by indexing into the NDArray.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/<span style="color: #7F0055; font-weight: bold;">get</span> x 3<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: () cpu() float32
3.
</pre>
</div>
</div>

<div id="outline-container-org9c9b160" class="outline-3">
<h3 id="org9c9b160"><span class="section-number-3">1.3.</span> Length, Dimensionality, and Shape</h3>
<div class="outline-text-3" id="text-1-3">
<p>
Let us revisit some concepts from <a href="2.1-data-manipulation.html">Section 2.1</a>. A vector is just an
array of numbers. And just as every array has a length, so does every
vector. In math notation, if we want to say that a vector \(\mathbf{x}\)
consists of \(n\) real-valued scalars, we can express this as
\(\mathbf{x} \in \mathbb{R}^n\). The length of a vector is commonly
called the <b>dimension</b> of the vector.
</p>

<p>
As with an ordinary Java array, we can access the length. In the case
of a NDArray we can achieve this by using the <code>(size ndarray 0)</code>
function, where \(0\) means the axis-0.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/size x<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
4
</pre>


<p>
When a NDArray represents a vector (with precisely one axis), we can
also access its length via the <code>shape</code> function. The shape lists the
length (dimensionality) along each axis of the NDArray. For NDArrays
with just one axis, the shape has just one element.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/shape x<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
(4)
</pre>


<p>
or we can use <code>get-shape</code> function:
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/get-shape x<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
(4)
</pre>


<p>
Note that the word &ldquo;dimension&rdquo; tends to get overloaded in these
contexts and this tends to confuse people. To clarify, we use the
dimensionality of a <i>vector</i> or an <i>axis</i> to refer to its length, i.e.,
the number of elements of a vector or an axis. However, we use the
dimensionality of a NDArray to refer to the number of axes that a
NDArray has. In this sense, the dimensionality of some axis of a
NDArray will be the length of that axis.
</p>
</div>
</div>

<div id="outline-container-orgeed1b80" class="outline-3">
<h3 id="orgeed1b80"><span class="section-number-3">1.4.</span> Matrices</h3>
<div class="outline-text-3" id="text-1-4">
<p>
Just as vectors generalize scalars from order zero to order one,
matrices generalize vectors from order one to order two. Matrices,
which we will typically denote with bold-faced, capital letters (e.g.,
\(\mathbf{X}\), \(\mathbf{Y}\), and \(\mathbf{Z}\)), are represented in code
as NDArray with two axes.
</p>

<p>
In math notation, we use \(\mathbf{A} \in \mathbb{R}^{m \times n}\) to
express that the matrix \(\mathbf{A}\) consists of \(m\) rows and \(n\)
columns of real-valued scalars. Visually, we can illustrate any matrix
\(\mathbf{A} \in \mathbb{R}^{m \times n}\) as a table, where each
element \(a_{ij}\) belongs to the \(i\)<sup>th</sup> row and \(j\)<sup>th</sup> column:
</p>

\begin{equation}
  \mathbf{A}=
  \begin{bmatrix}
    a_{11} & a_{12} & \cdots & a_{1n} \\
    a_{21} & a_{22} & \cdots & a_{2n} \\
    \vdots & \vdots & \ddots & \vdots \\
    a_{m1} & a_{m2} & \cdots & a_{mn} \\
  \end{bmatrix}.
\end{equation}

<p>
For any \(\mathbf{A} \in \mathbb{R}^{m \times n}\), the shape of
\(\mathbf{A}\) is \((m, n)\) or \(m \times n\). Specifically, when a matrix
has the same number of rows and columns, its shape becomes a square;
thus, it is called a <b>square matrix</b>.
</p>

<p>
We can create an \(m \times n\) matrix by specifying a shape with two
components \(m\) and \(n\) when calling any of our favorite functions for
instantiating a NDArray.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">A</span> <span style="color: #7388d6;">(</span><span style="color: #7F0055; font-weight: bold;">-&gt;</span> <span style="color: #909183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/arange ndm 20.<span style="color: #909183;">)</span>
           <span style="color: #909183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/reshape 5 4<span style="color: #909183;">)</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
A
</pre>
</div>

<pre class="example">
ND: (5, 4) cpu() float32
[[ 0.,  1.,  2.,  3.],
 [ 4.,  5.,  6.,  7.],
 [ 8.,  9., 10., 11.],
 [12., 13., 14., 15.],
 [16., 17., 18., 19.],
]
</pre>


<p>
We can access the scalar element \(a_{ij}\) of a matrix \(\mathbf{A}\) in
(2.3.2) by specifying the indices for the row (\(i\)) and column (\(j\)),
such as \([\mathbf{A}]_{ij}\). When the scalar elements of a matrix
\(\mathbf{A}\), such as in (2.3.2), are not given, we may simply use the
lower-case letter of the matrix \(\mathbf{A}\) with the index subscript,
\(a_{ij}\), to refer to \([\mathbf{A}]_{ij}\). To keep notation simple,
commas are inserted to separate indices only when necessary, such as
\(a_{2,3j}\) and \([\mathbf{A}]_{2i−1,3}\).
</p>

<p>
Sometimes, we want to flip the axes. When we exchange a matrix&rsquo;s rows
and columns, the result is called the transpose of the
matrix. Formally, we signify a matrix \(\mathbf{A}\)&rsquo;s transpose by
\(\mathbf{A}^\top\) and if \(\mathbf{B}=\mathbf{A}^\top\), then
\(b_{ij}=a_{ji}\) for any \(i\) and \(j\). Thus, the transpose of
\(\mathbf{A}\) in (2.3.2) is a \(n \times m\) matrix:
</p>

\begin{equation}
  \mathbf{A}^\top =
  \begin{bmatrix}
    a_{11} & a_{21} & \dots  & a_{m1} \\
    a_{12} & a_{22} & \dots  & a_{m2} \\
    \vdots & \vdots & \ddots  & \vdots \\
    a_{1n} & a_{2n} & \dots  & a_{mn}
  \end{bmatrix}.
\end{equation}

<p>
Now we access a matrix&rsquo;s transpose in code.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/transpose A<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: (4, 5) cpu() float32
[[ 0.,  4.,  8., 12., 16.],
 [ 1.,  5.,  9., 13., 17.],
 [ 2.,  6., 10., 14., 18.],
 [ 3.,  7., 11., 15., 19.],
]
</pre>


<p>
There is also a simplified function for the same purpose:
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/t A<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: (4, 5) cpu() float32
[[ 0.,  4.,  8., 12., 16.],
 [ 1.,  5.,  9., 13., 17.],
 [ 2.,  6., 10., 14., 18.],
 [ 3.,  7., 11., 15., 19.],
]
</pre>


<p>
As a special type of the square matrix, a <b>symmetric matrix</b>
\(\mathbf{A}\) is equal to its transpose:
\(\mathbf{A}=\mathbf{A}^\top\). Here we define a symmetric matrix
\(\mathbf{B}\).
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">B</span> <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/create ndm <span style="color: #909183;">[</span><span style="color: #709870;">[</span>1 2 3<span style="color: #709870;">]</span> <span style="color: #709870;">[</span>2 0 4<span style="color: #709870;">]</span> <span style="color: #709870;">[</span>3 4 5<span style="color: #709870;">]</span><span style="color: #909183;">]</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
B
</pre>
</div>

<pre class="example">
ND: (3, 3) cpu() int64
[[ 1,  2,  3],
 [ 2,  0,  4],
 [ 3,  4,  5],
]
</pre>


<p>
Now we compare \(\mathbf{B}\) with its transpose.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/= B <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/t B<span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: (3, 3) cpu() boolean
[[ true,  true,  true],
 [ true,  true,  true],
 [ true,  true,  true],
]
</pre>


<p>
Matrices are useful data structures: they allow us to organize data
that have different modalities of variation. For example, rows in our
matrix might correspond to different houses (data examples), while
columns might correspond to different attributes. This should sound
familiar if you have ever used spreadsheet software or have read
Section 2.2. Thus, although the default orientation of a single vector
is a column vector, in a matrix that represents a tabular dataset, it
is more conventional to treat each data example as a row vector in the
matrix. And, as we will see in later chapters, this convention will
enable common deep learning practices. For example, along the
outermost axis of a NDArray, we can access or enumerate minibatches of
data examples, or just data examples if no minibatch exists.
</p>
</div>
</div>

<div id="outline-container-org988f23b" class="outline-3">
<h3 id="org988f23b"><span class="section-number-3">1.5.</span> Tensors / NDArrays</h3>
<div class="outline-text-3" id="text-1-5">
<p>
Just as vectors generalize scalars, and matrices generalize vectors,
we can build data structures with even more axes. NDArrays (&ldquo;NDArrays&rdquo;
in this subsection refer to algebraic objects) give us a generic way
of describing $n$-dimensional arrays with an arbitrary number of
axes. Vectors, for example, are first-order NDArrays, and matrices are
second-order NDArrays. NDArrays are denoted with capital letters of a
special font face (e.g., \(\mathbf{X}\), \(\mathbf{Y}\), and \(\mathbf{Z}\))
and their indexing mechanism (e.g., \(x_{ijk}\) and \([X]_{1,2i−1,3}\)) is
similar to that of matrices.
</p>

<p>
NDArrays will become more important when we start working with images,
which arrive as $n$-dimensional arrays with 3 axes corresponding to
the height, width, and a channel axis for stacking the color channels
(red, green, and blue). For now, we will skip over higher order
NDArrays and focus on the basics.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">X</span> <span style="color: #7388d6;">(</span><span style="color: #7F0055; font-weight: bold;">-&gt;</span> <span style="color: #909183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/arange ndm 24.<span style="color: #909183;">)</span>
           <span style="color: #909183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/reshape 2 3 4<span style="color: #909183;">)</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
X
</pre>
</div>

<pre class="example" id="orgb3db7b8">
ND: (2, 3, 4) cpu() float32
[[[ 0.,  1.,  2.,  3.],
  [ 4.,  5.,  6.,  7.],
  [ 8.,  9., 10., 11.],
 ],
 [[12., 13., 14., 15.],
  [16., 17., 18., 19.],
  [20., 21., 22., 23.],
 ],
]
</pre>
</div>
</div>


<div id="outline-container-org2aebf18" class="outline-3">
<h3 id="org2aebf18"><span class="section-number-3">1.6.</span> Basic Properties of Tensor Arithmetic</h3>
<div class="outline-text-3" id="text-1-6">
<p>
Scalars, vectors, matrices, and NDArrays (&ldquo;NDArrays&rdquo; in this
subsection refer to algebraic objects) of an arbitrary number of axes
have some nice properties that often come in handy. For example, you
might have noticed from the definition of an elementwise operation
that any elementwise unary operation does not change the shape of its
operand. Similarly, given any two NDArrays with the same shape, the
result of any binary elementwise operation will be a NDArray of that
same shape. For example, adding two matrices of the same shape
performs elementwise addition over these two matrices.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">A</span> <span style="color: #7388d6;">(</span><span style="color: #7F0055; font-weight: bold;">-&gt;</span> <span style="color: #909183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/arange ndm 20.<span style="color: #909183;">)</span>
           <span style="color: #909183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/reshape 5 4<span style="color: #909183;">)</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
<span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">B</span> <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/duplicate A<span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
</pre>
</div>

<div class="org-src-container">
<pre class="src src-clojure">A
</pre>
</div>


<pre class="example">
ND: (5, 4) cpu() float32
[[ 0.,  1.,  2.,  3.],
 [ 4.,  5.,  6.,  7.],
 [ 8.,  9., 10., 11.],
 [12., 13., 14., 15.],
 [16., 17., 18., 19.],
]
</pre>


<div class="org-src-container">
<pre class="src src-clojure">B
</pre>
</div>

<pre class="example">
ND: (5, 4) cpu() float32
[[ 0.,  1.,  2.,  3.],
 [ 4.,  5.,  6.,  7.],
 [ 8.,  9., 10., 11.],
 [12., 13., 14., 15.],
 [16., 17., 18., 19.],
]
</pre>


<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/+ A B<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: (5, 4) cpu() float32
[[ 0.,  2.,  4.,  6.],
 [ 8., 10., 12., 14.],
 [16., 18., 20., 22.],
 [24., 26., 28., 30.],
 [32., 34., 36., 38.],
]
</pre>


<p>
Specifically, elementwise multiplication of two matrices is called
their <i>Hadamard product</i> (math notation \(\odot\)). Consider matrix
\(\mathbf{B} \in \mathbb{R}^{m \times n}\) whose element of row \(i\) and
column \(j\) is \(b_{ij}\). The Hadamard product of matrices \(\mathbf{A}\)
(defined in (2.3.2)) and \(\mathbf{B}\)
</p>

\begin{equation}
   \mathbf{A} \odot \mathbf{B} =
   \begin{bmatrix}
       a_{11}  b_{11} & a_{12}  b_{12} & \dots  & a_{1n}  b_{1n} \\
       a_{21}  b_{21} & a_{22}  b_{22} & \dots  & a_{2n}  b_{2n} \\
       \vdots & \vdots & \ddots & \vdots \\
       a_{m1}  b_{m1} & a_{m2}  b_{m2} & \dots  & a_{mn}  b_{mn}
   \end{bmatrix}.
\end{equation}

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/* A B<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: (5, 4) cpu() float32
[[  0.,   1.,   4.,   9.],
 [ 16.,  25.,  36.,  49.],
 [ 64.,  81., 100., 121.],
 [144., 169., 196., 225.],
 [256., 289., 324., 361.],
]
</pre>


<p>
Multiplying or adding a NDArray by a scalar also does not change the
shape of the NDArray, where each element of the operand NDArray will
be added or multiplied by the scalar.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">a</span> 2<span style="color: #707183;">)</span>
<span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">X</span> <span style="color: #7388d6;">(</span><span style="color: #7F0055; font-weight: bold;">-&gt;</span> <span style="color: #909183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/arange ndm 24.<span style="color: #909183;">)</span>
           <span style="color: #909183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/reshape 2 3 4<span style="color: #909183;">)</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
<span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/+ X a<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example" id="org3f61308">
ND: (2, 3, 4) cpu() float32
[[[ 2.,  3.,  4.,  5.],
  [ 6.,  7.,  8.,  9.],
  [10., 11., 12., 13.],
 ],
 [[14., 15., 16., 17.],
  [18., 19., 20., 21.],
  [22., 23., 24., 25.],
 ],
]
</pre>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/shape <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/* X a<span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
(2, 3, 4)
</pre>
</div>
</div>


<div id="outline-container-lin-alg-reduction" class="outline-3">
<h3 id="lin-alg-reduction"><span class="section-number-3">1.7.</span> Reduction</h3>
<div class="outline-text-3" id="text-lin-alg-reduction">
<p>
One useful operation that we can perform with arbitrary NDArrays is to
calculate the sum of their elements. In mathematical notation, we
express sums using the \(\sum\) symbol. To express the sum of the
elements in a vector \(x\) of length \(d\), we write \(\sum^d_{i=1}
x_i\). In code, we can just call the function for calculating the sum.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">x</span> <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/arange ndm 4.<span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
x
</pre>
</div>

<pre class="example">
ND: (4) cpu() float32
[0., 1., 2., 3.]
</pre>


<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/sum x<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: () cpu() float32
6.
</pre>


<p>
We can express sums over the elements of NDArrays of arbitrary
shape. For example, the sum of the elements of an \(m \times n\) matrix
\(\mathbf{A}\) could be written \(\sum^m_{i=1} \sum^n_{j=1} a_{ij}\).
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/shape A<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
(5, 4)
</pre>


<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/sum A<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: () cpu() float32
190.
</pre>


<p>
By default, invoking the function for calculating the sum <i>reduces</i> a
NDArray along all its axes to a scalar. We can also specify the axes
along which the NDArray is reduced via summation. Take matrices as an
example. To reduce the row dimension (axis 0) by summing up elements
of all the rows, we specify <code>[0]</code> when invoking the function. Since the
input matrix reduces along axis 0 to generate the output vector, the
dimension of axis 0 of the input is lost in the output shape.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">A-sum-axis0</span> <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/sum A <span style="color: #909183;">[</span>0<span style="color: #909183;">]</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
A-sum-axis0
</pre>
</div>

<pre class="example">
ND: (4) cpu() float32
[40., 45., 50., 55.]
</pre>


<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/shape A-sum-axis0<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
(4)
</pre>


<p>
Specifying <code>[1]</code> will reduce the column dimension (axis 1) by summing up
elements of all the columns. Thus, the dimension of axis 1 of the
input is lost in the output shape.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">A-sum-axis1</span> <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/sum A <span style="color: #909183;">[</span>1<span style="color: #909183;">]</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
A-sum-axis1
</pre>
</div>

<pre class="example">
ND: (5) cpu() float32
[ 6., 22., 38., 54., 70.]
</pre>


<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/shape A-sum-axis1<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
(5)
</pre>


<p>
Reducing a matrix along both rows and columns via summation is
equivalent to summing up all the elements of the matrix.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/sum A <span style="color: #7388d6;">[</span>0 1<span style="color: #7388d6;">]</span><span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: () cpu() float32
190.
</pre>


<p>
A related quantity is the <b>mean</b>, which is also called the average. We
calculate the mean by dividing the sum by the total number of
elements. In code, we could just call the function for calculating the
mean on NDArrays of arbitrary shape.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/mean A<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: () cpu() float32
9.5
</pre>


<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>// <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/sum A<span style="color: #7388d6;">)</span> <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/size A<span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: () cpu() float32
9.5
</pre>


<p>
Likewise, the function for calculating the mean can also reduce a
NDArray along the specified axes.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/mean A <span style="color: #7388d6;">[</span>0<span style="color: #7388d6;">]</span><span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: (4) cpu() float32
[ 8.,  9., 10., 11.]
</pre>


<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/shape A<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
(5, 4)
</pre>



<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>// <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/sum A <span style="color: #909183;">[</span>0<span style="color: #909183;">]</span><span style="color: #7388d6;">)</span> <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/<span style="color: #7F0055; font-weight: bold;">get</span> <span style="color: #909183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/shape A<span style="color: #909183;">)</span> 0<span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: (4) cpu() float32
[ 8.,  9., 10., 11.]
</pre>
</div>


<div id="outline-container-lin-alg-non-reduction" class="outline-4">
<h4 id="lin-alg-non-reduction"><span class="section-number-4">1.7.1.</span> Non-Reduction Sum</h4>
<div class="outline-text-4" id="text-lin-alg-non-reduction">
<p>
However, sometimes it can be useful to keep the number of axes
unchanged when invoking the function for calculating the sum or mean.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">sum-A</span> <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/sum A <span style="color: #909183;">[</span>1<span style="color: #909183;">]</span> <span style="color: #110099;">true</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
sum-A
</pre>
</div>

<pre class="example">
ND: (5, 1) cpu() float32
[[ 6.],
 [22.],
 [38.],
 [54.],
 [70.],
]
</pre>


<p>
For instance, since <code>sum-A</code> still keeps its two axes after summing each
row, we can divide <code>A</code> by <code>sum-A</code> with broadcasting.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>// A sum-A<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: (5, 4) cpu() float32
[[0.    , 0.1667, 0.3333, 0.5   ],
 [0.1818, 0.2273, 0.2727, 0.3182],
 [0.2105, 0.2368, 0.2632, 0.2895],
 [0.2222, 0.2407, 0.2593, 0.2778],
 [0.2286, 0.2429, 0.2571, 0.2714],
]
</pre>


<p>
If we want to calculate the cumulative sum of elements of A along some
axis, say axis 0 (row by row), we can call the <code>cumsum</code> function. This
function will not reduce the input NDArray along any axis.
</p>

<div class="org-src-container">
<pre class="src src-clojure">A
</pre>
</div>

<pre class="example">
ND: (5, 4) cpu() float32
[[ 0.,  1.,  2.,  3.],
 [ 4.,  5.,  6.,  7.],
 [ 8.,  9., 10., 11.],
 [12., 13., 14., 15.],
 [16., 17., 18., 19.],
]
</pre>



<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/cumsum A 0<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: (5, 4) cpu() float32
[[ 0.,  1.,  2.,  3.],
 [ 4.,  6.,  8., 10.],
 [12., 15., 18., 21.],
 [24., 28., 32., 36.],
 [40., 45., 50., 55.],
]
</pre>


<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/cumsum A 1<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: (5, 4) cpu() float32
[[ 0.,  1.,  3.,  6.],
 [ 4.,  9., 15., 22.],
 [ 8., 17., 27., 38.],
 [12., 25., 39., 54.],
 [16., 33., 51., 70.],
]
</pre>
</div>
</div>
</div>


<div id="outline-container-org8b72aeb" class="outline-3">
<h3 id="org8b72aeb"><span class="section-number-3">1.8.</span> Dot Products</h3>
<div class="outline-text-3" id="text-1-8">
<p>
So far, we have only performed elementwise operations, sums, and
averages. And if this was all we could do, linear algebra probably
would not deserve its own section. However, one of the most
fundamental operations is the dot product. Given two vectors \(x,y \in
\mathbb{R}^d\), their dot product \(x^\top y\) (or \(\langle x,y \rangle\))
is a sum over the products of the elements at the same position:
\(x^\top y = \sum^d_{i=1} x_i y_i\).
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">y</span> <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/ones ndm <span style="color: #909183;">[</span>4<span style="color: #909183;">]</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
#'clj-d2l.linear-algebra/y
</pre>


<div class="org-src-container">
<pre class="src src-clojure">x
</pre>
</div>

<pre class="example">
ND: (4) cpu() float32
[0., 1., 2., 3.]
</pre>


<div class="org-src-container">
<pre class="src src-clojure">y
</pre>
</div>

<pre class="example">
ND: (4) cpu() float32
[1., 1., 1., 1.]
</pre>


<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/dot x y<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: () cpu() float32
6.
</pre>


<p>
Note that we can express the dot product of two vectors equivalently
by performing an elementwise multiplication and then a sum:
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/sum <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/* x y<span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: () cpu() float32
6.
</pre>


<p>
Dot products are useful in a wide range of contexts. For example,
given some set of values, denoted by a vector \(x \in \mathbb{R}^d\) and
a set of weights denoted by \(w \in \mathbb{R}^d\), the weighted sum of
the values in \(x\) according to the weights \(w\) could be expressed as
the dot product \(x^\top w\). When the weights are non-negative and sum
to one (i.e., (\(\sum^d_{i=1} w_i = 1\))), the dot product expresses a
weighted average. After normalizing two vectors to have the unit
length, the dot products express the cosine of the angle between
them. We will formally introduce this notion of length later in this
section.
</p>
</div>
</div>

<div id="outline-container-org069ddea" class="outline-3">
<h3 id="org069ddea"><span class="section-number-3">1.9.</span> Matrix-Vector Products</h3>
<div class="outline-text-3" id="text-1-9">
<p>
Now that we know how to calculate dot products, we can begin to
understand matrix-vector products. Recall the matrix \(\mathbf{A} \in
\mathbb{R}^{m \times n}\) and the vector \(x \in \mathbb{R}^n\) defined
and visualized in (2.3.2) and (2.3.1) respectively. Let us start off
by visualizing the matrix \(\mathbf{A}\) in terms of its row vectors
</p>

\begin{equation}
  \mathbf{A}=
  \begin{bmatrix}
    \mathbf{a}^\top_{1} \\
    \mathbf{a}^\top_{2} \\
    \vdots \\
    \mathbf{a}^\top_m \\
  \end{bmatrix},
\end{equation}

<p>
where each \(\mathbf{a}^\top_i \in \mathbb{R}^n\) is a row vector
representing the \(i\)<sup>th</sup> row of the matrix \(\mathbf{A}\). The
matrix-vector product \(\mathbf{A}\mathbf{x}\) is simply a column vector
of length \(m\), whose \(i\)<sup>th</sup> element is the dot product
\(\mathbf{a}^top_i \mathbf{x}\):
</p>

\begin{equation}
  \mathbf{A}\mathbf{x}
  = \begin{bmatrix}
    \mathbf{a}^\top_{1} \\
    \mathbf{a}^\top_{2} \\
    \vdots \\
    \mathbf{a}^\top_m \\
  \end{bmatrix}\mathbf{x}
  = \begin{bmatrix}
    \mathbf{a}^\top_{1} \mathbf{x}  \\
    \mathbf{a}^\top_{2} \mathbf{x} \\
    \vdots\\
    \mathbf{a}^\top_{m} \mathbf{x}\\
  \end{bmatrix}.
\end{equation}

<p>
We can think of multiplication by a matrix \(\mathbf{A} \in
\mathbb{R}^{m \times n}\) as a transformation that projects vectors
from \(\mathbb{R}^n\) to \(\mathbb{R}^m\). These transformations turn out
to be remarkably useful. For example, we can represent rotations as
multiplications by a square matrix. As we will see in subsequent
chapters, we can also use matrix-vector products to describe the most
intensive calculations required when computing each layer in a neural
network given the values of the previous layer.
</p>

<p>
Expressing matrix-vector products in code with NDArrays, we use the
same dot function as for dot products. When we call <code>(nd/dot A x)</code> with
a matrix \(\mathbf{A}\) and a vector \(\mathbf{x}\), the matrix-vector
product is performed. Note that the column dimension of \(\mathbf{A}\)
(its length along axis 1) must be the same as the dimension of
\(\mathbf{x}\) (its length).
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/shape A<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
(5, 4)
</pre>


<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/shape x<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
(4)
</pre>


<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/dot A x<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: (5) cpu() float32
[ 14.,  38.,  62.,  86., 110.]
</pre>
</div>
</div>


<div id="outline-container-org179830c" class="outline-3">
<h3 id="org179830c"><span class="section-number-3">1.10.</span> Matrix-Matrix Multiplication</h3>
<div class="outline-text-3" id="text-1-10">
<p>
If you have gotten the hang of dot products and matrix-vector
products, then matrix-matrix multiplication should be straightforward.
</p>

<p>
Say that we have two matrices \(\mathbf{A} \in \mathbb{R}^{n \times k}\)
and \(\mathbf{B} \in \mathbb{R}^{k \times m}\):
</p>

\begin{equation}
   \mathbf{A}=\begin{bmatrix}
    a_{11} & a_{12} & \cdots & a_{1k} \\
    a_{21} & a_{22} & \cdots & a_{2k} \\
   \vdots & \vdots & \ddots & \vdots \\
    a_{n1} & a_{n2} & \cdots & a_{nk} \\
   \end{bmatrix},\quad
   \mathbf{B}=\begin{bmatrix}
    b_{11} & b_{12} & \cdots & b_{1m} \\
    b_{21} & b_{22} & \cdots & b_{2m} \\
   \vdots & \vdots & \ddots & \vdots \\
    b_{k1} & b_{k2} & \cdots & b_{km} \\
   \end{bmatrix}.
\end{equation}

<p>
Denote by \(\mathbf{a}^\top_i \in \mathbb{R}^k\) the row vector
representing the \(i\)<sup>th</sup> row of the matrix \(\mathbf{A}\), and let
\(\mathbf{b}_j \in \mathbb{R}^k\) be the column vector from the \(j\)<sup>th</sup>
column of the matrix \(\mathbf{B}\). To produce the matrix product
\(\mathbf{C}=\mathbf{AB}\), it is easiest to think of \(\mathbf{A}\) in
terms of its row vectors and \(\mathbf{B}\) in terms of its column
vectors:
</p>

\begin{equation}
   \mathbf{A}=
   \begin{bmatrix}
   \mathbf{a}^\top_{1} \\
   \mathbf{a}^\top_{2} \\
   \vdots \\
   \mathbf{a}^\top_n \\
   \end{bmatrix},
   \quad \mathbf{B}=\begin{bmatrix}
    \mathbf{b}_{1} & \mathbf{b}_{2} & \cdots & \mathbf{b}_{m} \\
   \end{bmatrix}.
\end{equation}

<p>
Then the matrix product \(\mathbf{C} \in \mathbb{R}^{n \times m}\) is
produced as we simply compute each element \(c_{ij}\) as the dot product
\(\mathbf{a}^\top_i \mathbf{b}_j\):
</p>

\begin{equation}
   \mathbf{C} = \mathbf{AB} = \begin{bmatrix}
   \mathbf{a}^\top_{1} \\
   \mathbf{a}^\top_{2} \\
   \vdots \\
   \mathbf{a}^\top_n \\
   \end{bmatrix}
   \begin{bmatrix}
    \mathbf{b}_{1} & \mathbf{b}_{2} & \cdots & \mathbf{b}_{m} \\
   \end{bmatrix}
   = \begin{bmatrix}
   \mathbf{a}^\top_{1} \mathbf{b}_1 & \mathbf{a}^\top_{1}\mathbf{b}_2& \cdots & \mathbf{a}^\top_{1} \mathbf{b}_m \\
    \mathbf{a}^\top_{2}\mathbf{b}_1 & \mathbf{a}^\top_{2} \mathbf{b}_2 & \cdots & \mathbf{a}^\top_{2} \mathbf{b}_m \\
    \vdots & \vdots & \ddots &\vdots\\
   \mathbf{a}^\top_{n} \mathbf{b}_1 & \mathbf{a}^\top_{n}\mathbf{b}_2& \cdots& \mathbf{a}^\top_{n} \mathbf{b}_m
   \end{bmatrix}.
\end{equation}

<p>
We can think of the matrix-matrix multiplication \(\mathbf{AB}\) as
simply performing \(m\) matrix-vector products and stitching the results
together to form an \(n \times m\) matrix. In the following snippet, we
perform matrix multiplication on \(\mathbf{A}\) and \(\mathbf{B}\). Here,
\(\mathbf{A}\) is a matrix with 5 rows and 4 columns, and \(\mathbf{B}\)
is a matrix with 4 rows and 3 columns. After multiplication, we obtain
a matrix with 5 rows and 3 columns.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">B</span> <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/ones ndm <span style="color: #909183;">[</span>4 3<span style="color: #909183;">]</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
B
</pre>
</div>

<pre class="example">
ND: (4, 3) cpu() float32
[[1., 1., 1.],
 [1., 1., 1.],
 [1., 1., 1.],
 [1., 1., 1.],
]
</pre>


<div class="org-src-container">
<pre class="src src-clojure">A
</pre>
</div>

<pre class="example">
ND: (5, 4) cpu() float32
[[ 0.,  1.,  2.,  3.],
 [ 4.,  5.,  6.,  7.],
 [ 8.,  9., 10., 11.],
 [12., 13., 14., 15.],
 [16., 17., 18., 19.],
]
</pre>


<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/dot A B<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: (5, 3) cpu() float32
[[ 6.,  6.,  6.],
 [22., 22., 22.],
 [38., 38., 38.],
 [54., 54., 54.],
 [70., 70., 70.],
]
</pre>


<p>
Matrix-matrix multiplication can be simply called matrix
multiplication, and should not be confused with the Hadamard product.
</p>
</div>
</div>


<div id="outline-container-org01d1f21" class="outline-3">
<h3 id="org01d1f21"><span class="section-number-3">1.11.</span> Norms</h3>
<div class="outline-text-3" id="text-1-11">
<p>
Some of the most useful operators in linear algebra are
norms. Informally, the <b>norm of a vector</b> tells us how big a vector
is. The notion of size under consideration here concerns not
dimensionality but rather the magnitude of the components.
</p>

<p>
In linear algebra, a vector norm is a function \(f\) that maps a vector
to a scalar, satisfying a handful of properties. Given any vector
\(\mathbf{x}\), the first property says that if we scale all the
elements of a vector by a constant factor \(\alpha\), its norm also
scales by the absolute value of the same constant factor:
</p>

\begin{equation}
f(\alpha \mathbf{x}) = |\alpha| f(\mathbf{x}).
\end{equation}

<p>
The second property is the familiar triangle inequality:
</p>

\begin{equation}
f(\mathbf{x} + \mathbf{y}) \leq f(\mathbf{x}) + f(\mathbf{y}).
\end{equation}

<p>
The third property simply says that the norm must be non-negative:
</p>

\begin{equation}
f(\mathbf{x}) \geq 0.
\end{equation}

<p>
That makes sense, as in most contexts the smallest size for anything
is 0. The final property requires that the smallest norm is achieved
and only achieved by a vector consisting of all zeros.
</p>

\begin{equation}
\forall i, [\mathbf{x}]_i = 0 \Leftrightarrow f(\mathbf{x})=0.
\end{equation}

<p>
You might notice that norms sound a lot like measures of distance. And
if you remember Euclidean distances (think Pythagoras&rsquo; theorem) from
grade school, then the concepts of non-negativity and the triangle
inequality might ring a bell. In fact, the Euclidean distance is a
norm: specifically it is the \(L_2\) norm. Suppose that the elements in
the $n$-dimensional vector \(\mathbf{x}\) are \(x_1, \ldots, x_n\). The
\(L_2\) norm of \(\mathbf{x}\) is the square root of the sum of the
squares of the vector elements:
</p>

\begin{equation}
\|\mathbf{x}\|_2 = \sqrt{\sum_{i=1}^n x_i^2},
\end{equation}

<p>
where the subscript \(2\) is often omitted in \(L_2\) norms, i.e.,
\(\|\mathbf{x}\|\) is equivalent to \(\|\mathbf{x}\|_2\). In code, we can
calculate the \(L_2\) norm of a vector as follows.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">defn</span> <span style="color: #0000ff; font-weight: bold;">l2norm</span> <span style="color: #7388d6;">[</span>ndarray<span style="color: #7388d6;">]</span>
  <span style="color: #7388d6;">(</span><span style="color: #7F0055; font-weight: bold;">-&gt;</span> ndarray
      <span style="color: #909183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/pow 2<span style="color: #909183;">)</span>
      <span style="color: #909183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/sum<span style="color: #909183;">)</span>
      <span style="color: #909183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/sqrt<span style="color: #909183;">)</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
</pre>
</div>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">u</span> <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/create ndm <span style="color: #909183;">[</span>3. -4.<span style="color: #909183;">]</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
u
</pre>
</div>

<pre class="example">
ND: (2) cpu() float64
[ 3., -4.]
</pre>


<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span>l2norm u<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: () cpu() float64
5.
</pre>


<p>
In deep learning, we work more often with the squared \(L_2\) norm. You
will also frequently encounter the \(L_1\) norm, which is expressed as
the sum of the absolute values of the vector elements:
</p>

\begin{equation}
\|\mathbf{x}\|_1 = \sum_{i=1}^n \left|x_i \right|.
\end{equation}

<p>
As compared with the \(L_2\) norm, it is less influenced by outliers. To
calculate the \(L_1\) norm, we compose the absolute value function with
a sum over the elements.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/sum <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/abs u<span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: () cpu() float64
7.
</pre>


<p>
Both the \(L_2\) norm and the \(L_1\) norm are special cases of the more
general \(L_p\) norm:
</p>

\begin{equation}
\|\mathbf{x}\|_p = \left(\sum_{i=1}^n \left|x_i \right|^p \right)^{1/p}.
\end{equation}

<p>
Analogous to \(L_2\) norms of vectors, the <i>Frobenius norm</i> of a matrix
\(\mathbf{X} \in \mathbb{R}^{m \times n}\) is the square root of the sum
of the squares of the matrix elements:
</p>

\begin{equation}
\|\mathbf{X}\|_F = \sqrt{\sum_{i=1}^m \sum_{j=1}^n x_{ij}^2}.
\end{equation}

<p>
The Frobenius norm satisfies all the properties of vector norms. It
behaves as if it were an \(L_2\) norm of a matrix-shaped
vector. Invoking the following function will calculate the Frobenius
norm of a matrix.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span>l2norm <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/ones ndm <span style="color: #909183;">[</span>4 9<span style="color: #909183;">]</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: () cpu() float32
6.
</pre>
</div>
</div>

<div id="outline-container-org5fbc90e" class="outline-3">
<h3 id="org5fbc90e"><span class="section-number-3">1.12.</span> Norms and Objectives</h3>
<div class="outline-text-3" id="text-1-12">
<p>
While we do not want to get too far ahead of ourselves, we can plant
some intuition already about why these concepts are useful. In deep
learning, we are often trying to solve optimization problems: <b>maximize</b>
the probability assigned to observed data; <b>minimize</b> the distance
between predictions and the ground-truth observations. Assign vector
representations to items (like words, products, or news articles) such
that the distance between similar items is minimized, and the distance
between dissimilar items is maximized. Oftentimes, the objectives,
perhaps the most important components of deep learning algorithms
(besides the data), are expressed as norms.
</p>
</div>
</div>

<div id="outline-container-org0f3a939" class="outline-3">
<h3 id="org0f3a939"><span class="section-number-3">1.13.</span> More on Linear Algebra</h3>
<div class="outline-text-3" id="text-1-13">
<p>
In just this section, we have taught you all the linear algebra that
you will need to understand a remarkable chunk of modern deep
learning. There is a lot more to linear algebra and a lot of that
mathematics is useful for machine learning. For example, matrices can
be decomposed into factors, and these decompositions can reveal
low-dimensional structure in real-world datasets. There are entire
subfields of machine learning that focus on using matrix
decompositions and their generalizations to high-order NDArrays to
discover structure in datasets and solve prediction problems. But this
book focuses on deep learning. And we believe you will be much more
inclined to learn more mathematics once you have gotten your hands
dirty deploying useful machine learning models on real datasets. So
while we reserve the right to introduce more mathematics much later
on, we will wrap up this section here.
</p>

<p>
If you are eager to learn more about linear algebra, you may refer to
either the online appendix on linear algebraic operations or other
excellent resources [Strang, 1993][Kolter, 2008][Petersen et al.,
2008].
</p>
</div>
</div>

<div id="outline-container-org3769a94" class="outline-3">
<h3 id="org3769a94"><span class="section-number-3">1.14.</span> Summary</h3>
<div class="outline-text-3" id="text-1-14">
<ul class="org-ul">
<li>Scalars, vectors, matrices, and NDArrays are basic mathematical
objects in linear algebra.</li>
<li>Vectors generalize scalars, and matrices generalize vectors.</li>
<li>Scalars, vectors, matrices, and NDArrays have zero, one, two, and an
arbitrary number of axes, respectively.</li>
<li>A NDArray can be reduced along the specified axes by sum and mean.</li>
<li>Elementwise multiplication of two matrices is called their Hadamard
product. It is different from matrix multiplication.</li>
<li>In deep learning, we often work with norms such as the \(L_1\) norm,
the \(L_2\) norm, and the Frobenius norm.</li>
<li>We can perform a variety of operations over scalars, vectors,
matrices, and NDArrays.</li>
</ul>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Kimi Ma</p>
<p class="date">Created: 2022-05-17 Tue 07:53</p>
</div>
</body>
</html>
