<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2022-05-17 Tue 07:53 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>&lrm;</title>
<meta name="author" content="Kimi Ma" />
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
</style>
<link rel="stylesheet" type="text/css" href="css/style.css" />
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="org-div-home-and-up">
 <a accesskey="h" href="sitemap.html"> UP </a>
 |
 <a accesskey="H" href="index.html"> HOME </a>
</div><div id="content" class="content">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#orgc61528a">1. Implementation of Softmax Regression from Scratch</a>
<ul>
<li><a href="#orgfeb4edd">1.1. Initializing Model Parameters</a></li>
<li><a href="#org78da4f1">1.2. Defining the Softmax Operation</a></li>
<li><a href="#org9c12bf7">1.3. Defining the Model</a></li>
<li><a href="#org94a4691">1.4. Defining the Loss Function</a></li>
<li><a href="#org13883db">1.5. Classification Accuracy</a></li>
<li><a href="#org498f41b">1.6. Training</a></li>
<li><a href="#orgab93769">1.7. Prediction</a></li>
<li><a href="#org912150a">1.8. Summary</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-orgc61528a" class="outline-2">
<h2 id="orgc61528a"><span class="section-number-2">1.</span> Implementation of Softmax Regression from Scratch</h2>
<div class="outline-text-2" id="text-1">
<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">ns</span> <span style="color: #000000; font-style: italic; text-decoration: underline;">clj-d2l.softmax-from-scratch</span>
  <span style="color: #7388d6;">(</span><span style="color: #110099;">:require</span> <span style="color: #909183;">[</span>clojure.java.io <span style="color: #110099;">:as</span> io<span style="color: #909183;">]</span>
            <span style="color: #909183;">[</span>clj-djl.ndarray <span style="color: #110099;">:as</span> nd<span style="color: #909183;">]</span>
            <span style="color: #909183;">[</span>clj-djl.training.dataset <span style="color: #110099;">:as</span> ds<span style="color: #909183;">]</span>
            <span style="color: #909183;">[</span>clj-djl.model <span style="color: #110099;">:as</span> model<span style="color: #909183;">]</span>
            <span style="color: #909183;">[</span>clj-djl.nn <span style="color: #110099;">:as</span> nn<span style="color: #909183;">]</span>
            <span style="color: #909183;">[</span>clj-djl.training.loss <span style="color: #110099;">:as</span> loss<span style="color: #909183;">]</span>
            <span style="color: #909183;">[</span>clj-djl.training.tracker <span style="color: #110099;">:as</span> tracker<span style="color: #909183;">]</span>
            <span style="color: #909183;">[</span>clj-djl.training.optimizer <span style="color: #110099;">:as</span> optimizer<span style="color: #909183;">]</span>
            <span style="color: #909183;">[</span>clj-djl.training <span style="color: #110099;">:as</span> t<span style="color: #909183;">]</span>
            <span style="color: #909183;">[</span>clj-djl.training.listener <span style="color: #110099;">:as</span> listener<span style="color: #909183;">]</span>
            <span style="color: #909183;">[</span>clj-djl.engine <span style="color: #110099;">:as</span> engine<span style="color: #909183;">]</span>
            <span style="color: #909183;">[</span>clj-d2l.core <span style="color: #110099;">:as</span> d2l<span style="color: #909183;">]</span><span style="color: #7388d6;">)</span>
  <span style="color: #7388d6;">(</span><span style="color: #110099;">:import</span> <span style="color: #909183;">[</span>ai.djl.basicdataset.cv.classification FashionMnist<span style="color: #909183;">]</span>
           <span style="color: #909183;">[</span>java.nio.file Paths<span style="color: #909183;">]</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
</pre>
</div>

<div class="org-src-container">
<pre class="src src-emacs-lisp"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">setq</span> org-babel-clojure-sync-nrepl-timeout 1000<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
1000
</pre>


<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">batch-size</span> 256<span style="color: #707183;">)</span>
<span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">fashion-mnist</span> <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">d2l</span>/load-data-fashion-mnist batch-size<span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
</pre>
</div>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">#&rsquo;clj-d2l.softmax-from-scratch/batch-size</td>
</tr>

<tr>
<td class="org-left">#&rsquo;clj-d2l.softmax-from-scratch/fashion-mnist</td>
</tr>
</tbody>
</table>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span>.size <span style="color: #7388d6;">(</span><span style="color: #7F0055; font-weight: bold;">first</span> fashion-mnist<span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
60000
</pre>
</div>

<div id="outline-container-orgfeb4edd" class="outline-3">
<h3 id="orgfeb4edd"><span class="section-number-3">1.1.</span> Initializing Model Parameters</h3>
<div class="outline-text-3" id="text-1-1">
<p>
As in our linear regression example, each example here will be
represented by a fixed-length vector. Each example in the raw dataset
is a \(28 \times 28\) image. In this section, we will flatten each
image, treating them as vectors of length 784. In the future, we will
talk about more sophisticated strategies for exploiting the spatial
structure in images, but for now we treat each pixel location as just
another feature.
</p>

<p>
Recall that in softmax regression, we have as many outputs as there are
classes. Because our dataset has 10 classes, our network will have an
output dimension of 10. Consequently, our weights will constitute a
\(784 \times 10\) matrix and the biases will constitute a
\(1 \times 10\) row vector. As with linear regression, we will
initialize our weights <code>W</code> with Gaussian noise and our biases to take
the initial value 0.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">num-inputs</span> 784<span style="color: #707183;">)</span>
<span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">num-outputs</span> 10<span style="color: #707183;">)</span>
<span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">ndm</span> <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/base-manager<span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
<span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">W</span> <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/random-normal ndm 0 0.01 <span style="color: #909183;">[</span>num-inputs num-outputs<span style="color: #909183;">]</span> <span style="color: #110099;">:float32</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
<span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">b</span> <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/zeros ndm <span style="color: #909183;">[</span>num-outputs<span style="color: #909183;">]</span> <span style="color: #110099;">:float32</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-org78da4f1" class="outline-3">
<h3 id="org78da4f1"><span class="section-number-3">1.2.</span> Defining the Softmax Operation</h3>
<div class="outline-text-3" id="text-1-2">
<p>
Before implementing the softmax regression model, let us briefly
review how the sum operator works along specific dimensions in a
tensor, as discussed in Section
<a href="2.3-linear-algebra.html#lin-alg-reduction">2.3-linear-algebra.html#lin-alg-reduction</a> and Section
<a href="2.3-linear-algebra.html#lin-alg-non-reduction">2.3-linear-algebra.html#lin-alg-non-reduction</a>. Given a matrix <code>X</code>
we can sum over all elements (by default) or only over elements in the
same axis, i.e., the same column (axis 0) or the same row (axis
1). Note that if <code>X</code> is a tensor with shape (2, 3) and we sum over the
columns, the result will be a vector with shape (3,). When invoking
the sum operator, we can specify to keep the number of axes in the
original tensor, rather than collapsing out the dimension that we
summed over. This will result in a two-dimensional tensor with shape
(1, 3).
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">X</span> <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/create ndm <span style="color: #909183;">[</span><span style="color: #709870;">[</span>1 2 3<span style="color: #709870;">]</span> <span style="color: #709870;">[</span>4 5 6<span style="color: #709870;">]</span><span style="color: #909183;">]</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
</pre>
</div>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/sum X <span style="color: #7388d6;">[</span>0<span style="color: #7388d6;">]</span> <span style="color: #110099;">true</span><span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: (1, 3) cpu() int64
[[ 5,  7,  9],
]
</pre>


<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/sum X <span style="color: #7388d6;">[</span>1<span style="color: #7388d6;">]</span> <span style="color: #110099;">true</span><span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: (2, 1) cpu() int64
[[ 6],
 [15],
]
</pre>


<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/sum X <span style="color: #7388d6;">[</span>0 1<span style="color: #7388d6;">]</span> <span style="color: #110099;">true</span><span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: (1, 1) cpu() int64
[[21],
]
</pre>


<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/sum X <span style="color: #7388d6;">[</span>0 1<span style="color: #7388d6;">]</span> <span style="color: #110099;">false</span><span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: () cpu() int64
21
</pre>


<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/sum X<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: () cpu() int64
21
</pre>


<p>
We are now ready to implement the softmax operation. Recall that
softmax consists of three steps: (i) we exponentiate each term (using
<code>exp</code>); (ii) we sum over each row (we have one row per example in the
batch) to get the normalization constant for each example; (iii) we
divide each row by its normalization constant, ensuring that the
result sums to 1.  Before looking at the code, let us recall how this
looks expressed as an equation:
</p>

\begin{equation}
\label{org7db6f3c}
\mathrm{softmax}(\mathbf{X})_{ij} = \frac{\exp(\mathbf{X}_{ij})}{\sum_k \exp(\mathbf{X}_{ik})}.
\end{equation}

<p>
The denominator, or normalization constant, is also sometimes called
the <b>partition function</b> (and its logarithm is called the log-partition
function). The origins of that name are in <a href="https://en.wikipedia.org/wiki/Partition_function_(statistical_mechanics)">statistical physics</a> where a
related equation models the distribution over an ensemble of
particles.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">defn</span> <span style="color: #0000ff; font-weight: bold;">softmax</span> <span style="color: #7388d6;">[</span>ndarray<span style="color: #7388d6;">]</span>
  <span style="color: #7388d6;">(</span><span style="color: #7F0055; font-weight: bold;">let</span> <span style="color: #909183;">[</span>Xexp <span style="color: #709870;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/exp ndarray<span style="color: #709870;">)</span>
        partition <span style="color: #709870;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/sum Xexp <span style="color: #907373;">[</span>1<span style="color: #907373;">]</span> <span style="color: #110099;">true</span><span style="color: #709870;">)</span><span style="color: #909183;">]</span>
    <span style="color: #909183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>// Xexp partition<span style="color: #909183;">)</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
#'clj-d2l.softmax-from-scratch/softmax
</pre>


<p>
As you can see, for any random input, we turn each element into a
non-negative number. Moreover, each row sums up to 1, as is required
for a probability.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">X</span> <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/random-normal ndm <span style="color: #909183;">[</span>2 5<span style="color: #909183;">]</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
<span style="color: #707183;">(</span>softmax X<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: (2, 5) cpu() float32
[[0.2492, 0.2315, 0.2786, 0.0503, 0.1905],
 [0.1874, 0.4392, 0.2314, 0.0868, 0.0552],
]
</pre>


<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/sum <span style="color: #7388d6;">(</span>softmax X<span style="color: #7388d6;">)</span> <span style="color: #7388d6;">[</span>1<span style="color: #7388d6;">]</span><span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: (2) cpu() float32
[1., 1.]
</pre>


<p>
Note that while this looks correct mathematically, we were a bit
sloppy in our implementation because we failed to take precautions
against numerical overflow or underflow due to large or very small
elements of the matrix.
</p>
</div>
</div>

<div id="outline-container-org9c12bf7" class="outline-3">
<h3 id="org9c12bf7"><span class="section-number-3">1.3.</span> Defining the Model</h3>
<div class="outline-text-3" id="text-1-3">
<p>
Now that we have defined the softmax operation, we can implement the
softmax regression model. The below code defines how the input is
mapped to the output through the network. Note that we flatten each
original image in the batch into a vector using the <code>reshape</code> function
before passing the data through our model.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">defn</span> <span style="color: #0000ff; font-weight: bold;">net</span> <span style="color: #7388d6;">[</span>ndarray<span style="color: #7388d6;">]</span>
  <span style="color: #7388d6;">(</span><span style="color: #7F0055; font-weight: bold;">let</span> <span style="color: #909183;">[</span>current-W W
        current-b b<span style="color: #909183;">]</span>
    <span style="color: #909183;">(</span><span style="color: #7F0055; font-weight: bold;">-&gt;</span> ndarray
        <span style="color: #709870;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/reshape <span style="color: #907373;">[</span>-1 num-inputs<span style="color: #907373;">]</span><span style="color: #709870;">)</span>
        <span style="color: #709870;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/dot current-W<span style="color: #709870;">)</span>
        <span style="color: #709870;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/+ current-b<span style="color: #709870;">)</span>
        softmax<span style="color: #909183;">)</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-org94a4691" class="outline-3">
<h3 id="org94a4691"><span class="section-number-3">1.4.</span> Defining the Loss Function</h3>
<div class="outline-text-3" id="text-1-4">
<p>
Next, we need to implement the cross-entropy loss function, as
introduced in Section
<a href="3.4-softmax-regression.html#sec-softmax">3.4-softmax-regression.html#sec-softmax</a>. This may be the
most common loss function in all of deep learning because, at the
moment, classification problems far outnumber regression problems.
</p>

<p>
Recall that cross-entropy takes the negative log-likelihood of the
predicted probability assigned to the true label. Rather than
iterating over the predictions with a for-loop (which tends to be
inefficient), we can pick all elements by a single operator. Below, we
create sample data <code>y-hat</code> with 2 examples of predicted probabilities
over 3 classes and their corresponding labels <code>y</code>. With <code>y</code> we know that
in the first example the first class is the correct prediction and in
the second example the third class is the ground-truth. Using <code>y</code> as the
indices of the probabilities in <code>y-hat</code>, we pick the probability of the
first class in the first example and the probability of the third
class in the second example.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">y</span> <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/create ndm <span style="color: #909183;">[</span>0 2<span style="color: #909183;">]</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
<span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">y-hat</span> <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/create ndm <span style="color: #909183;">[</span><span style="color: #709870;">[</span>0.1 0.3 0.6<span style="color: #709870;">][</span>0.3 0.2 0.5<span style="color: #709870;">]</span><span style="color: #909183;">]</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
<span style="color: #707183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/<span style="color: #7F0055; font-weight: bold;">get</span> y-hat <span style="color: #2A00FF;">":,{}"</span> y<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: (2, 1) cpu() float64
[[0.1],
 [0.5],
]
</pre>


<p>
Now we can implement the cross-entropy loss function efficiently with
just one line of code.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">defn</span> <span style="color: #0000ff; font-weight: bold;">cross-entropy</span> <span style="color: #7388d6;">[</span>y-hat y<span style="color: #7388d6;">]</span>
  <span style="color: #7388d6;">(</span><span style="color: #7F0055; font-weight: bold;">-&gt;</span> <span style="color: #909183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/<span style="color: #7F0055; font-weight: bold;">get</span> y-hat <span style="color: #2A00FF;">":, {}"</span> <span style="color: #709870;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/to-type y <span style="color: #110099;">:int32</span> <span style="color: #110099;">false</span><span style="color: #709870;">)</span><span style="color: #909183;">)</span>
      <span style="color: #909183;">(</span>.log<span style="color: #909183;">)</span>
      <span style="color: #909183;">(</span>.neg<span style="color: #909183;">)</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>

<span style="color: #707183;">(</span>cross-entropy y-hat y<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
ND: (2, 1) cpu() float64
[[2.3026],
 [0.6931],
]
</pre>
</div>
</div>


<div id="outline-container-org13883db" class="outline-3">
<h3 id="org13883db"><span class="section-number-3">1.5.</span> Classification Accuracy</h3>
<div class="outline-text-3" id="text-1-5">
<p>
Given the predicted probability distribution <code>y-hat</code>, we typically
choose the class with the highest predicted probability whenever we
must output a hard prediction. Indeed, many applications require that
we make a choice. Gmail must categorize an email into &ldquo;Primary&rdquo;,
&ldquo;Social&rdquo;, &ldquo;Updates&rdquo;, or &ldquo;Forums&rdquo;. It might estimate probabilities
internally, but at the end of the day it has to choose one among the
classes.
</p>

<p>
When predictions are consistent with the label class <code>y</code>, they are
correct. The classification accuracy is the fraction of all
predictions that are correct. Although it can be difficult to optimize
accuracy directly (it is not differentiable), it is often the
performance measure that we care most about, and we will nearly always
report it when training classifiers.
</p>

<p>
To compute accuracy we do the following. First, if <code>y-hat</code> is a matrix,
we assume that the second dimension stores prediction scores for each
class. We use <code>argmax</code> to obtain the predicted class by the index for
the largest entry in each row. Then we compare the predicted class
with the ground-truth <code>y</code> elementwise. Since the equality operator <code>==</code> is
sensitive to data types, we convert <code>y-hat</code>&rsquo;s data type to match that of
<code>y</code>. The result is a tensor containing entries of 0 (false) and 1
(true). Taking the sum yields the number of correct predictions.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">defn</span> <span style="color: #0000ff; font-weight: bold;">accuracy</span> <span style="color: #7388d6;">[</span>y-hat y<span style="color: #7388d6;">]</span>
  <span style="color: #7388d6;">(</span><span style="color: #7F0055; font-weight: bold;">if</span> <span style="color: #909183;">(</span>&gt; <span style="color: #709870;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/size <span style="color: #907373;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/shape y-hat<span style="color: #907373;">)</span><span style="color: #709870;">)</span> 1<span style="color: #909183;">)</span>
    <span style="color: #909183;">(</span><span style="color: #7F0055; font-weight: bold;">-&gt;</span> <span style="color: #709870;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/argmax y-hat 1<span style="color: #709870;">)</span>
        <span style="color: #709870;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/= <span style="color: #907373;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/to-type y <span style="color: #110099;">:int64</span> <span style="color: #110099;">false</span><span style="color: #907373;">)</span><span style="color: #709870;">)</span>
        <span style="color: #709870;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/sum<span style="color: #709870;">)</span>
        <span style="color: #709870;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/get-element<span style="color: #709870;">)</span><span style="color: #909183;">)</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
</pre>
</div>

<p>
We will continue to use the variables <code>y-hat</code> and <code>y</code> defined before as
the predicted probability distributions and labels, respectively. We
can see that the first example&rsquo;s prediction class is 2 (the largest
element of the row is 0.6 with the index 2), which is inconsistent
with the actual label, 0. The second example&rsquo;s prediction class is 2
(the largest element of the row is 0.5 with the index of 2), which is
consistent with the actual label, 2. Therefore, the classification
accuracy rate for these two examples is 0.5.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span>/ <span style="color: #7388d6;">(</span>accuracy y-hat y<span style="color: #7388d6;">)</span> <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/size y<span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
1/2
</pre>


<p>
Similarly, we can evaluate the accuracy for any model net on a dataset
that is accessed via the data iterator <code>data-iter</code>.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">fashion-mnist-train</span> <span style="color: #7388d6;">(</span><span style="color: #7F0055; font-weight: bold;">first</span> fashion-mnist<span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
<span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">defn</span> <span style="color: #0000ff; font-weight: bold;">evaluate-accuracy</span> <span style="color: #7388d6;">[</span>net data-iter<span style="color: #7388d6;">]</span>
  <span style="color: #7388d6;">(</span><span style="color: #7F0055; font-weight: bold;">let</span> <span style="color: #909183;">[</span>acc <span style="color: #709870;">(</span><span style="color: #7F0055; font-weight: bold;">atom</span> <span style="color: #907373;">[</span>0 0<span style="color: #907373;">]</span><span style="color: #709870;">)</span><span style="color: #909183;">]</span>
    <span style="color: #909183;">(</span><span style="color: #7F0055; font-weight: bold;">doseq</span> <span style="color: #709870;">[</span>batch data-iter<span style="color: #709870;">]</span>
      <span style="color: #709870;">(</span><span style="color: #7F0055; font-weight: bold;">let</span> <span style="color: #907373;">[</span>X <span style="color: #6276ba;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/head <span style="color: #858580;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">ds</span>/get-data batch<span style="color: #858580;">)</span><span style="color: #6276ba;">)</span>
            y <span style="color: #6276ba;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/head <span style="color: #858580;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">ds</span>/get-labels batch<span style="color: #858580;">)</span><span style="color: #6276ba;">)</span><span style="color: #907373;">]</span>
        <span style="color: #907373;">(</span><span style="color: #7F0055; font-weight: bold;">swap!</span> acc update 0 + <span style="color: #6276ba;">(</span>accuracy <span style="color: #858580;">(</span>net X<span style="color: #858580;">)</span> y<span style="color: #6276ba;">)</span><span style="color: #907373;">)</span>
        <span style="color: #907373;">(</span><span style="color: #7F0055; font-weight: bold;">swap!</span> acc update 1 + <span style="color: #6276ba;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/size y<span style="color: #6276ba;">)</span><span style="color: #907373;">)</span>
        <span style="color: #907373;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">ds</span>/close batch<span style="color: #907373;">)</span><span style="color: #709870;">)</span><span style="color: #909183;">)</span>
    <span style="color: #909183;">(</span><span style="color: #7F0055; font-weight: bold;">reduce</span> / @acc<span style="color: #909183;">)</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
#'clj-d2l.softmax-from-scratch/evaluate-accuracy
</pre>


<p>
Here <code>accumulate</code> is a utility function to accumulate sums over multiple
variables. In the above <code>evaluate-accuracy</code> function, we create a <code>atom</code>
of vector with 2 variables for storing both the number of correct
predictions and the number of predictions, respectively. Both will be
accumulated over time as we iterate over the dataset.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">defn</span> <span style="color: #0000ff; font-weight: bold;">accumulate</span> <span style="color: #7388d6;">[</span>atom x y z<span style="color: #7388d6;">]</span>
  <span style="color: #7388d6;">(</span><span style="color: #7F0055; font-weight: bold;">swap!</span> atom update 0 + x<span style="color: #7388d6;">)</span>
  <span style="color: #7388d6;">(</span><span style="color: #7F0055; font-weight: bold;">swap!</span> atom update 1 + y<span style="color: #7388d6;">)</span>
  <span style="color: #7388d6;">(</span><span style="color: #7F0055; font-weight: bold;">swap!</span> atom update 2 + z<span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
</pre>
</div>

<p>
Because we initialized the net model with random weights, the accuracy
of this model should be close to random guessing, i.e., 0.1 for 10
classes.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span>evaluate-accuracy net <span style="color: #7388d6;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">ds</span>/get-data-iterator <span style="color: #909183;">(</span><span style="color: #7F0055; font-weight: bold;">second</span> fashion-mnist<span style="color: #909183;">)</span> ndm<span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
119/2000
</pre>
</div>
</div>

<div id="outline-container-org498f41b" class="outline-3">
<h3 id="org498f41b"><span class="section-number-3">1.6.</span> Training</h3>
<div class="outline-text-3" id="text-1-6">
<p>
The training loop for softmax regression should look strikingly
familiar if you read through our implementation of linear regression
in Section 3.2. Here we refactor the implementation to make it
reusable. First, we define a function to train for one epoch. Note
that updater is a general function to update the model parameters,
which accepts the batch size as an argument. It can be either a
wrapper of the <code>d2l/sgd</code> function or a framework&rsquo;s built-in optimization
function.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">defn</span> <span style="color: #0000ff; font-weight: bold;">train-epoch-ch3</span> <span style="color: #7388d6;">[</span>net train-iter lr loss updater<span style="color: #7388d6;">]</span>
  <span style="color: #7388d6;">(</span><span style="color: #7F0055; font-weight: bold;">let</span> <span style="color: #909183;">[</span>acc <span style="color: #709870;">(</span><span style="color: #7F0055; font-weight: bold;">atom</span> <span style="color: #907373;">[</span>0 0 0<span style="color: #907373;">]</span><span style="color: #709870;">)</span><span style="color: #909183;">]</span>
    <span style="color: #909183;">(</span><span style="color: #7F0055; font-weight: bold;">doseq</span> <span style="color: #709870;">[</span>param <span style="color: #907373;">[</span>W b<span style="color: #907373;">]</span><span style="color: #709870;">]</span>
      <span style="color: #709870;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/set-requires-gradient param <span style="color: #110099;">true</span><span style="color: #709870;">)</span><span style="color: #909183;">)</span>
    <span style="color: #909183;">(</span><span style="color: #7F0055; font-weight: bold;">doseq</span> <span style="color: #709870;">[</span>batch <span style="color: #907373;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">t</span>/iter-seq train-iter<span style="color: #907373;">)</span><span style="color: #709870;">]</span>
      <span style="color: #709870;">(</span><span style="color: #7F0055; font-weight: bold;">let</span> <span style="color: #907373;">[</span>X <span style="color: #6276ba;">(</span><span style="color: #7F0055; font-weight: bold;">-&gt;</span> batch <span style="color: #000000; font-style: italic; text-decoration: underline;">ds</span>/get-data <span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/head <span style="color: #858580;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/reshape <span style="color: #80a880;">[</span>-1 num-inputs<span style="color: #80a880;">]</span><span style="color: #858580;">)</span><span style="color: #6276ba;">)</span>
            y <span style="color: #6276ba;">(</span><span style="color: #7F0055; font-weight: bold;">-&gt;</span> batch <span style="color: #000000; font-style: italic; text-decoration: underline;">ds</span>/get-labels <span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/head<span style="color: #6276ba;">)</span><span style="color: #907373;">]</span>
        <span style="color: #907373;">(</span><span style="color: #7F0055; font-weight: bold;">with-open</span> <span style="color: #6276ba;">[</span>gc <span style="color: #858580;">(</span><span style="color: #7F0055; font-weight: bold;">-&gt;</span> <span style="color: #80a880;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">engine</span>/get-instance<span style="color: #80a880;">)</span> <span style="color: #80a880;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">engine</span>/new-gradient-collector<span style="color: #80a880;">)</span><span style="color: #858580;">)</span><span style="color: #6276ba;">]</span>
          <span style="color: #6276ba;">(</span><span style="color: #7F0055; font-weight: bold;">let</span> <span style="color: #858580;">[</span>y-hat <span style="color: #80a880;">(</span>net X<span style="color: #80a880;">)</span>
                l <span style="color: #80a880;">(</span>loss y-hat y<span style="color: #80a880;">)</span><span style="color: #858580;">]</span>
            <span style="color: #858580;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">t</span>/backward gc l<span style="color: #858580;">)</span>
            <span style="color: #858580;">(</span>accumulate acc <span style="color: #80a880;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/get-element <span style="color: #887070;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/sum l<span style="color: #887070;">)</span><span style="color: #80a880;">)</span> <span style="color: #80a880;">(</span>accuracy y-hat y<span style="color: #80a880;">)</span> <span style="color: #80a880;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/size y<span style="color: #80a880;">)</span><span style="color: #858580;">)</span><span style="color: #6276ba;">)</span><span style="color: #907373;">)</span><span style="color: #709870;">)</span>
      <span style="color: #709870;">(</span>updater <span style="color: #907373;">[</span>W b<span style="color: #907373;">]</span> lr batch-size<span style="color: #709870;">)</span>
      <span style="color: #709870;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">ds</span>/close batch<span style="color: #709870;">)</span><span style="color: #909183;">)</span>
    <span style="color: #909183;">[</span><span style="color: #709870;">(</span>/ <span style="color: #907373;">(</span>@acc 0<span style="color: #907373;">)</span> <span style="color: #907373;">(</span>@acc 2<span style="color: #907373;">)</span><span style="color: #709870;">)</span> <span style="color: #709870;">(</span>/ <span style="color: #907373;">(</span>@acc 1<span style="color: #907373;">)</span> <span style="color: #907373;">(</span>@acc 2<span style="color: #907373;">)</span><span style="color: #709870;">)</span><span style="color: #909183;">]</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
</pre>
</div>

<p>
The training function then runs multiple epochs and visualize the
training progress.
</p>

<p>
Again, we use the minibatch stochastic gradient descent to optimize
the loss function of the model. Note that the number of epochs
(numEpochs), and learning rate (lr) are both adjustable
hyper-parameters. By changing their values, we may be able to increase
the classification accuracy of the model. In practice we will want to
split our data three ways into training, validation, and test data,
using the validation data to choose the best values of our
hyper-parameters.
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">defn</span> <span style="color: #0000ff; font-weight: bold;">sgd</span> <span style="color: #7388d6;">[</span>params lr batch-size<span style="color: #7388d6;">]</span>
  <span style="color: #7388d6;">(</span><span style="color: #7F0055; font-weight: bold;">doseq</span> <span style="color: #909183;">[</span>param params<span style="color: #909183;">]</span>
    <span style="color: #909183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/-! param <span style="color: #709870;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>// <span style="color: #907373;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/* <span style="color: #6276ba;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/get-gradient param<span style="color: #6276ba;">)</span> lr<span style="color: #907373;">)</span> batch-size<span style="color: #709870;">)</span><span style="color: #909183;">)</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
</pre>
</div>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">defn</span> <span style="color: #0000ff; font-weight: bold;">train-ch3</span> <span style="color: #7388d6;">[</span>net train-ds test-ds lr loss num-epochs updater<span style="color: #7388d6;">]</span>
  <span style="color: #7388d6;">(</span><span style="color: #7F0055; font-weight: bold;">doseq</span> <span style="color: #909183;">[</span>i <span style="color: #709870;">(</span><span style="color: #7F0055; font-weight: bold;">range</span> num-epochs<span style="color: #709870;">)</span><span style="color: #909183;">]</span>
    <span style="color: #909183;">(</span><span style="color: #7F0055; font-weight: bold;">let</span> <span style="color: #709870;">[</span>train-metrics <span style="color: #907373;">(</span>train-epoch-ch3 net <span style="color: #6276ba;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">ds</span>/get-data-iterator train-ds ndm<span style="color: #6276ba;">)</span> lr loss updater<span style="color: #907373;">)</span>
          accuracy <span style="color: #907373;">(</span>evaluate-accuracy net <span style="color: #6276ba;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">ds</span>/get-data-iterator test-ds ndm<span style="color: #6276ba;">)</span><span style="color: #907373;">)</span>
          train-accuracy <span style="color: #907373;">(</span><span style="color: #7F0055; font-weight: bold;">get</span> train-metrics 1<span style="color: #907373;">)</span>
          train-loss <span style="color: #907373;">(</span><span style="color: #7F0055; font-weight: bold;">get</span> train-metrics 0<span style="color: #907373;">)</span><span style="color: #709870;">]</span>
      <span style="color: #709870;">(</span><span style="color: #7F0055; font-weight: bold;">println</span> <span style="color: #2A00FF;">"Epoch "</span> i <span style="color: #2A00FF;">": Test Accuracy: "</span> accuracy<span style="color: #709870;">)</span>
      <span style="color: #709870;">(</span><span style="color: #7F0055; font-weight: bold;">println</span> <span style="color: #2A00FF;">"Train Accuracy: "</span> train-accuracy<span style="color: #709870;">)</span>
      <span style="color: #709870;">(</span><span style="color: #7F0055; font-weight: bold;">println</span> <span style="color: #2A00FF;">"Train Loss: "</span>train-loss<span style="color: #709870;">)</span><span style="color: #909183;">)</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
</pre>
</div>


<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">num-epochs</span> 3<span style="color: #707183;">)</span>
<span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">lr</span> 0.1<span style="color: #707183;">)</span>
<span style="color: #707183;">(</span>train-ch3 net <span style="color: #7388d6;">(</span><span style="color: #7F0055; font-weight: bold;">first</span> fashion-mnist<span style="color: #7388d6;">)</span> <span style="color: #7388d6;">(</span><span style="color: #7F0055; font-weight: bold;">second</span> fashion-mnist<span style="color: #7388d6;">)</span> lr cross-entropy num-epochs sgd<span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
Epoch  0 : Test Accuracy:  2067/2500
Train Accuracy:  10117/12000
Train Loss:  0.4646147914886475
Epoch  1 : Test Accuracy:  1041/1250
Train Accuracy:  25369/30000
Train Loss:  0.4579694811503092
Epoch  2 : Test Accuracy:  4169/5000
Train Accuracy:  25367/30000
Train Loss:  0.45321130771636964
</pre>
</div>
</div>

<div id="outline-container-orgab93769" class="outline-3">
<h3 id="orgab93769"><span class="section-number-3">1.7.</span> Prediction</h3>
<div class="outline-text-3" id="text-1-7">
<p>
Now that training is complete, our model is ready to classify some
images. Given a series of images, we will compare their actual labels
(first line of text output) and the model predictions (second line of
text output).
</p>

<div class="org-src-container">
<pre class="src src-clojure"><span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">defn</span> <span style="color: #0000ff; font-weight: bold;">predict-ch3</span> <span style="color: #7388d6;">[</span>net dataset ndmanager<span style="color: #7388d6;">]</span>
  <span style="color: #7388d6;">(</span><span style="color: #7F0055; font-weight: bold;">let</span> <span style="color: #909183;">[</span>batch <span style="color: #709870;">(</span><span style="color: #7F0055; font-weight: bold;">first</span> <span style="color: #907373;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">ds</span>/get-data-iterator dataset ndmanager<span style="color: #907373;">)</span><span style="color: #709870;">)</span>
        X <span style="color: #709870;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/head <span style="color: #907373;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">ds</span>/get-data batch<span style="color: #907373;">)</span><span style="color: #709870;">)</span>
        y-hat <span style="color: #709870;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/argmax <span style="color: #907373;">(</span>net X<span style="color: #907373;">)</span> 1<span style="color: #709870;">)</span>
        y <span style="color: #709870;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/head <span style="color: #907373;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">ds</span>/get-labels batch<span style="color: #907373;">)</span><span style="color: #709870;">)</span><span style="color: #909183;">]</span>
    <span style="color: #909183;">[</span>y-hat y<span style="color: #909183;">]</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>

<span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">def</span> <span style="color: #000000;">prediction</span> <span style="color: #7388d6;">(</span>predict-ch3 net <span style="color: #909183;">(</span><span style="color: #7F0055; font-weight: bold;">second</span> fashion-mnist<span style="color: #909183;">)</span> ndm<span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
<span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">println</span> <span style="color: #2A00FF;">"Prediction:   "</span> <span style="color: #7388d6;">(</span><span style="color: #7F0055; font-weight: bold;">take</span> 20 <span style="color: #909183;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/to-vec <span style="color: #709870;">(</span>prediction 0<span style="color: #709870;">)</span><span style="color: #909183;">)</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
<span style="color: #707183;">(</span><span style="color: #7F0055; font-weight: bold;">println</span> <span style="color: #2A00FF;">"Actual label: "</span><span style="color: #7388d6;">(</span><span style="color: #7F0055; font-weight: bold;">take</span> 20 <span style="color: #909183;">(</span><span style="color: #7F0055; font-weight: bold;">map</span> int <span style="color: #709870;">(</span><span style="color: #000000; font-style: italic; text-decoration: underline;">nd</span>/to-vec <span style="color: #907373;">(</span>prediction 1<span style="color: #907373;">)</span><span style="color: #709870;">)</span><span style="color: #909183;">)</span><span style="color: #7388d6;">)</span><span style="color: #707183;">)</span>
</pre>
</div>

<pre class="example">
Prediction:    (3 4 3 0 7 1 5 3 9 7 8 0 5 3 4 8 1 0 4 4)
Actual label:  (3 4 3 0 7 1 5 3 9 7 8 0 5 3 2 8 1 6 2 4)
</pre>
</div>
</div>

<div id="outline-container-org912150a" class="outline-3">
<h3 id="org912150a"><span class="section-number-3">1.8.</span> Summary</h3>
<div class="outline-text-3" id="text-1-8">
<p>
With softmax regression, we can train models for multi-category
classification. The training loop is very similar to that in linear
regression: retrieve and read data, define models and loss functions,
then train models using optimization algorithms. As you will soon find
out, most common deep learning models have similar training
procedures.
</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Kimi Ma</p>
<p class="date">Created: 2022-05-17 Tue 07:53</p>
</div>
</body>
</html>
