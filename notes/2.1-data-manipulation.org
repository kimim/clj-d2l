 #+TITLE: Data Manipulation
#+PROPERTY: header-args    :tangle src/clj_d2l/data_manipulation.clj

* Data Manipulation

In order to get anything done, we need some way to store and
manipulate data. Generally, there are two important things we need
to do with data: (i) acquire them; and (ii) process them once they
are inside the computer. There is no point in acquiring data without
some way to store it, so let us get our hands dirty first by playing
with synthetic data. To start, we introduce the $n$-dimensional
array, which is also called the /ndarray/.

If you have worked with NumPy, the most widely-used scientific
computing package in Python, then you will find this section
familiar. No matter which framework you use, its tensor class
(/ndarray/ in MXNet, DJL and clj-djl, /Tensor/ in both PyTorch and
TensorFlow) is similar to NumPy's ndarray with a few killer
features. First, GPU is well-supported to accelerate the computation
whereas NumPy only supports CPU computation. Second, the tensor
class supports automatic differentiation. These properties make the
tensor class suitable for deep learning. Throughout the book, when
we say ndarrays, we are referring to instances of the ndarray class
unless otherwise stated.

** Getting Started

In this section, we aim to get you up and running, equipping you
with the basic math and numerical computing tools that you will
build on as you progress through the book. Do not worry if you
struggle to grok some of the mathematical concepts or library
functions. The following sections will revisit this material in the
context of practical examples and it will sink. On the other hand,
if you already have some background and want to go deeper into the
mathematical content, just skip this section.

To start, we import the ndarray namespace from clj-djl. Here, the
ndarray namespace includes functions supported by clj-djl.

#+begin_src clojure :results silent
(ns clj-d2l.data-manipulation
  (:require [clj-djl.ndarray :as nd]))
#+end_src

An ndarray represents a (possibly multi-dimensional) array of
numerical values. With one axis, an ndarray corresponds (in math) to
a vector. With two axes, an ndarray corresponds to a
matrix. NDArrays with more than two axes do not have special
mathematical names.

To start, we can use arange to create a row vector x containing the
first 12 integers starting with 0. Each of the values in an ndarray
is called an element of the ndarray. For instance, there are 12
elements in the ndarray x. Unless otherwise specified, a new ndarray
will be stored in main memory and designated for CPU-based
computation.

#+begin_src clojure :results pp :exports both
(def ndm (nd/new-base-manager))
(def x (nd/arange ndm 0 12))
x
#+end_src

#+RESULTS:
: #object[ai.djl.mxnet.engine.MxNDArray 0x1c6d5df4 "ND: (12) cpu() int32\r\n[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]\r\n"]
:

We can access an ndarray's shape (the length along each axis) by
inspecting its shape property.

#+begin_src clojure :results value :exports both
(nd/get-shape x)
#+end_src

#+RESULTS:
: #object[ai.djl.ndarray.types.Shape 0x3648fafe "(12)"]

If we just want to know the total number of elements in an ndarray,
i.e., the product of all of the shape elements, we can inspect its
size. Because we are dealing with a vector here, the single element
of its shape is same to its size. The difference is that =get-shape=
will return a /Shape/ object.

#+begin_src clojure :results value
(nd/size x)
#+end_src

#+RESULTS:
: 12

To change the shape of an ndarray without altering either the number
of elements or their values, we can invoke the reshape function. For
example, we can transform our ndarray, x, from a row vector with
shape (12,) to a matrix with shape (3, 4). This new ndarray contains
the exact same values, but views them as a matrix organized as 3
rows and 4 columns. To reiterate, although the shape has changed,
the elements have not. Note that the size is unaltered by reshaping.

#+begin_src clojure :results pp :exports both
(def y (nd/reshape x [3 4]))
y
#+end_src

#+RESULTS:
: #object[ai.djl.mxnet.engine.MxNDArray 0x6ec18b16 "ND: (3, 4) cpu() int32\r\n[[ 0,  1,  2,  3],\r\n [ 4,  5,  6,  7],\r\n [ 8,  9, 10, 11],\r\n]\r\n"]
:

Reshaping by manually specifying every dimension is unnecessary. If
our target shape is a matrix with shape (height, width), then after
we know the width, the height is given implicitly. Why should we
have to perform the division ourselves? In the example above, to get
a matrix with 3 rows, we specified both that it should have 3 rows
and 4 columns. Fortunately, ndarrays can automatically work out one
dimension given the rest. We invoke this capability by placing -1
for the dimension that we would like ndarrays to automatically
infer. In our case, instead of calling x.reshape(3, 4), we could
have equivalently called =(nd/reshape x [-1 4])= or =(nd/reshape x [3
-1])=.

#+begin_src clojure :results pp :exports both
(def y (nd/reshape x [3 -1]))
y
#+end_src

#+RESULTS:
: #object[ai.djl.mxnet.engine.MxNDArray 0x27c4a644 "ND: (3, 4) cpu() int32\r\n[[ 0,  1,  2,  3],\r\n [ 4,  5,  6,  7],\r\n [ 8,  9, 10, 11],\r\n]\r\n"]
:

#+begin_src clojure :results output :exports both
(d2l/ps (nd/shape 2 3))
#+end_src

#+RESULTS:
: (2, 3)

#+begin_src clojure :results output :exports both
(d2l/ps (nd/create ndm (int-array [2 3])))
#+end_src

#+RESULTS:
: ND: (2) cpu() int32
: [ 2,  3]

Typically, we will want our matrices initialized either with zeros,
ones, some other constants, or numbers randomly sampled from a
specific distribution. We can create a ndarray representing a tensor
with all elements set to 0 and a shape of =[2 3 4]= as follows:
automatically inference the rest dimention specified with =-1=:

#+begin_src clojure :results output :exports both
(d2l/ps (nd/zeros ndm [2 3]))
(d2l/ps (nd/zeros ndm [2 3 4]))
(d2l/ps (nd/zeros ndm [2 2 2 2]))
#+end_src

#+RESULTS:
#+begin_example
ND: (2, 3) cpu() float32
[[0., 0., 0.],
 [0., 0., 0.],
]
ND: (2, 3, 4) cpu() float32
[[[0., 0., 0., 0.],
  [0., 0., 0., 0.],
  [0., 0., 0., 0.],
 ],
 [[0., 0., 0., 0.],
  [0., 0., 0., 0.],
  [0., 0., 0., 0.],
 ],
]
ND: (2, 2, 2, 2) cpu() float32
[[[[0., 0.],
   [0., 0.],
  ],
  [[0., 0.],
   [0., 0.],
  ],
 ],
 [[[0., 0.],
   [0., 0.],
  ],
  [[0., 0.],
   [0., 0.],
  ],
 ],
]
#+end_example

#+begin_src clojure :results output :exports both
(d2l/ps (nd/ones ndm [2 3]))
(d2l/ps (nd/ones ndm [2 3 4]))
(d2l/ps (nd/ones ndm [2 2 2 2]))
#+end_src

#+RESULTS:
#+begin_example
ND: (2, 3) cpu() float32
[[1., 1., 1.],
 [1., 1., 1.],
]
ND: (2, 3, 4) cpu() float32
[[[1., 1., 1., 1.],
  [1., 1., 1., 1.],
  [1., 1., 1., 1.],
 ],
 [[1., 1., 1., 1.],
  [1., 1., 1., 1.],
  [1., 1., 1., 1.],
 ],
]
ND: (2, 2, 2, 2) cpu() float32
[[[[1., 1.],
   [1., 1.],
  ],
  [[1., 1.],
   [1., 1.],
  ],
 ],
 [[[1., 1.],
   [1., 1.],
  ],
  [[1., 1.],
   [1., 1.],
  ],
 ],
]
#+end_example


#+begin_src clojure :results output :exports both
(d2l/ps (nd/random-normal ndm 0 1 [3 4] DataType/FLOAT32))
(d2l/ps (nd/random-normal ndm 0 1 [3 4] :float64))
#+end_src

#+RESULTS:
#+begin_example
ND: (3, 4) cpu() float32
[[ 2.2122,  1.1631,  0.774 ,  0.4838],
 [ 1.0434,  0.2996,  1.1839,  0.153 ],
 [ 1.8917, -1.1688, -1.2347,  1.5581],
]
ND: (3, 4) cpu() float64
[[-1.771 , -0.5459, -0.4514, -2.3556],
 [ 0.5794,  0.5414, -1.8561,  2.6785],
 [-1.9769,  1.2546, -0.208 , -0.5488],
]
#+end_example

#+begin_src clojure :results output :exports both
(d2l/ps (nd/random-normal ndm [3 4]))
#+end_src

#+RESULTS:
: ND: (3, 4) cpu() float32
: [[ 0.2444, -0.6811, -0.0372, -0.1353],
:  [-0.4877,  0.3772, -0.0226,  0.4102],
:  [ 0.5746,  0.5713,  1.4661, -2.758 ],
: ]

** Operations

#+begin_src clojure :results output :exports both
(d2l/ps (nd/create ndm (int-array [2 1 4 3]) (nd/shape [2 2])))
(d2l/ps (nd/create ndm [2 1 4 3] [2 2]))
(d2l/ps (nd/create ndm [(int 2) 1 4 3] [2 2]))
#+end_src

#+RESULTS:
#+begin_example
ND: (2, 2) cpu() int32
[[ 2,  1],
 [ 4,  3],
]
ND: (2, 2) cpu() int64
[[ 2,  1],
 [ 4,  3],
]
ND: (2, 2) cpu() int32
[[ 2,  1],
 [ 4,  3],
]
#+end_example

#+begin_src clojure :results output :exports both
(def x (nd/create ndm [1. 2 4 8] [2 2]))
(def y (nd/create ndm [2. 2 2 2] [2 2]))
(d2l/ps x)
(d2l/ps y)
(d2l/ps (nd/+ x y))
(d2l/ps (nd/- x y))
(d2l/ps (nd/* x y))
(d2l/ps (nd// x y))
(d2l/ps (nd/** x y))
(d2l/ps (nd/exp x))
#+end_src

#+RESULTS:
#+begin_example
ND: (2, 2) cpu() float64
[[1., 2.],
 [4., 8.],
]
ND: (2, 2) cpu() float64
[[2., 2.],
 [2., 2.],
]
ND: (2, 2) cpu() float64
[[ 3.,  4.],
 [ 6., 10.],
]
ND: (2, 2) cpu() float64
[[-1.,  0.],
 [ 2.,  6.],
]
ND: (2, 2) cpu() float64
[[ 2.,  4.],
 [ 8., 16.],
]
ND: (2, 2) cpu() float64
[[0.5, 1. ],
 [2. , 4. ],
]
ND: (2, 2) cpu() float64
[[ 1.,  4.],
 [16., 64.],
]
ND: (2, 2) cpu() float64
[[ 2.71828183e+00,  7.38905610e+00],
 [ 5.45981500e+01,  2.98095799e+03],
]
#+end_example

#+begin_src clojure :results output :exports both
(d2l/ps x)
(d2l/ps y)
(d2l/ps (nd/= x y))
#+end_src

#+RESULTS:
#+begin_example
ND: (2, 2) cpu() float64
[[1., 2.],
 [4., 8.],
]
ND: (2, 2) cpu() float64
[[2., 2.],
 [2., 2.],
]
ND: (2, 2) cpu() boolean
[[false,  true],
 [false, false],
]
#+end_example

#+begin_src clojure :results output :exports both
(def X (-> (nd/arange ndm 0 12) (nd/reshape [3 4])))
(def Y (nd/create ndm (int-array [2, 1, 4, 3, 1, 2, 3, 4, 4, 3, 2, 1]) [3 4]))
(d2l/ps (nd/concat X Y))
(d2l/ps (nd/concat X Y 0))
(d2l/ps (nd/concat X Y 1))
#+end_src

#+RESULTS:
#+begin_example
ND: (6, 4) cpu() int32
[[ 0,  1,  2,  3],
 [ 4,  5,  6,  7],
 [ 8,  9, 10, 11],
 [ 2,  1,  4,  3],
 [ 1,  2,  3,  4],
 [ 4,  3,  2,  1],
]
ND: (6, 4) cpu() int32
[[ 0,  1,  2,  3],
 [ 4,  5,  6,  7],
 [ 8,  9, 10, 11],
 [ 2,  1,  4,  3],
 [ 1,  2,  3,  4],
 [ 4,  3,  2,  1],
]
ND: (3, 8) cpu() int32
[[ 0,  1,  2,  3,  2,  1,  4,  3],
 [ 4,  5,  6,  7,  1,  2,  3,  4],
 [ 8,  9, 10, 11,  4,  3,  2,  1],
]
#+end_example

#+begin_src clojure :results output :exports both
(d2l/ps (nd/= X Y))
#+end_src

#+RESULTS:
: ND: (3, 4) cpu() boolean
: [[false,  true, false,  true],
:  [false, false, false, false],
:  [false, false, false, false],
: ]

#+begin_src clojure :results output :exports both
(d2l/ps (nd/sum X))
#+end_src

#+RESULTS:
: ND: () cpu() int32
: 66

** Broadcasting Mechanism

#+begin_src clojure :results output :exports both
(def a (-> (nd/arange ndm 3) (nd/reshape [3 1])))
(d2l/ps a)
(def b (-> (nd/arange ndm 2) (nd/reshape [1 2])))
(d2l/ps b)
(d2l/ps (nd/+ a b))
#+end_src

#+RESULTS:
#+begin_example
ND: (3, 1) cpu() int32
[[ 0],
 [ 1],
 [ 2],
]
ND: (1, 2) cpu() int32
[[ 0,  1],
]
ND: (3, 2) cpu() int32
[[ 0,  1],
 [ 1,  2],
 [ 2,  3],
]
#+end_example


** Indexing and Slicing

#+begin_src clojure :results output :exports both
(d2l/ps X)
(d2l/ps (nd/get X "-1"))
(d2l/ps (nd/get X "1:3"))
(d2l/ps (nd/set X "1,2" 9))
(d2l/ps (nd/set X "0:2,:" 12))
#+end_src

#+RESULTS:
#+begin_example
ND: (3, 4) cpu() int32
[[ 0,  1,  2,  3],
 [ 4,  5,  6,  7],
 [ 8,  9, 10, 11],
]
ND: (4) cpu() int32
[ 8,  9, 10, 11]
ND: (2, 4) cpu() int32
[[ 4,  5,  6,  7],
 [ 8,  9, 10, 11],
]
ND: (3, 4) cpu() int32
[[ 0,  1,  2,  3],
 [ 4,  5,  9,  7],
 [ 8,  9, 10, 11],
]
ND: (3, 4) cpu() int32
[[12, 12, 12, 12],
 [12, 12, 12, 12],
 [ 8,  9, 10, 11],
]
#+end_example


** Saving Memory

#+begin_src clojure :results output :exports both
(def original (nd/zeros ndm (nd/get-shape X)))
(def actual (nd/+ original X))
(d2l/ps original)
(d2l/ps actual)
(d2l/psl (identical? original actual))
(def copy (nd/+! original X))
(d2l/ps original)
(d2l/ps copy)
(d2l/psl (identical? original copy))
#+end_src

#+RESULTS:
#+begin_example
ND: (3, 4) cpu() float32
[[0., 0., 0., 0.],
 [0., 0., 0., 0.],
 [0., 0., 0., 0.],
]
ND: (3, 4) cpu() float32
[[12., 12., 12., 12.],
 [12., 12., 12., 12.],
 [ 8.,  9., 10., 11.],
]
false
ND: (3, 4) cpu() float32
[[12., 12., 12., 12.],
 [12., 12., 12., 12.],
 [ 8.,  9., 10., 11.],
]
ND: (3, 4) cpu() float32
[[12., 12., 12., 12.],
 [12., 12., 12., 12.],
 [ 8.,  9., 10., 11.],
]
true
#+end_example

#+begin_src clojure :results output :exports both
(def original (nd/zeros-like X))
(def actual (nd/+ original X))
(d2l/ps original)
(d2l/ps actual)
(println (identical? original actual))
(def copy (nd/+! original X))
(d2l/ps original)
(d2l/ps copy)
(println (identical? original copy))
#+end_src

#+RESULTS:
#+begin_example
ND: (3, 4) cpu() int32
[[ 0,  0,  0,  0],
 [ 0,  0,  0,  0],
 [ 0,  0,  0,  0],
]
ND: (3, 4) cpu() int32
[[12, 12, 12, 12],
 [12, 12, 12, 12],
 [ 8,  9, 10, 11],
]
false
ND: (3, 4) cpu() int32
[[12, 12, 12, 12],
 [12, 12, 12, 12],
 [ 8,  9, 10, 11],
]
ND: (3, 4) cpu() int32
[[12, 12, 12, 12],
 [12, 12, 12, 12],
 [ 8,  9, 10, 11],
]
true
#+end_example

** Conversion to Other Clojure Objects

#+begin_src clojure :results output :exports both

(d2l/psl (type (nd/to-vec X)))
(d2l/psl (nd/to-vec X))
(d2l/psl (type (nd/to-array X)))
(d2l/psl (type X))
(d2l/ps X)
#+end_src

#+RESULTS:
: class clojure.lang.PersistentVector
: [12 12 12 12 12 12 12 12 8 9 10 11]
: class [Ljava.lang.Integer;
: class ai.djl.mxnet.engine.MxNDArray
: ND: (3, 4) cpu() int32
: [[12, 12, 12, 12],
:  [12, 12, 12, 12],
:  [ 8,  9, 10, 11],
: ]

To convert a size-1 tensor to a scalar

#+begin_src clojure :results output :exports both
(def a (nd/create ndm [3.5]))
(d2l/ps a)
(println (nd/get-element a))
#+end_src

#+RESULTS:
: ND: (1) cpu() float64
: [3.5]
: 3.5
